\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{deneve2004bayesian}
\citation{ernst2002humans,battaglia2003bayesian,kording2004bayesian,alais2004ventriloquist,rowland2007bayesian,gu2008neural,fetsch2012neural}
\citation{kording2004bayesian,yon2021precision}
\citation{keller2018predictive}
\citation{eliades2008neural,keller2009neural,ayaz2019layer,audette2021temporally}
\citation{rao1999predictive,keller2018predictive}
\citation{keller2012sensorimotor,attinger2017visuomotor,jordan2020opposing,audette2021temporally}
\citation{markram2004interneurons,rudy2011three,pfeffer2013inhibition,jiang2015principles,tremblay2016gabaergic,campagnola2022local}
\citation{hertag2020learning,hertag2022prediction}
\citation{hollingworth1910central,jazayeri2010temporal,ashourian2011bayesian,petzschner2011iterative,akrami2018posterior,meirhaeghe2021precise}
\citation{hertag2020learning,hertag2022prediction}
\citation{larkum2013cellular,harris2015neocortical}
\citation{mumford1992computational,larkum2013cellular,friston2008hierarchical}
\citation{keller2018predictive}
\citation{larkum2013cellular}
\citation{tremblay2016gabaergic}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \DIFdelbeginFL  \DIFdelendFL  \DIFaddbeginFL  \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  Neural network model to track both the uncertainty of sensory inputs and predictions.\newline  } \DIFaddendFL  {\bf  (A)} Example illustration \DIFdelbeginFL  {\color {red}\sout {of }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {for }}\DIFaddendFL  context-dependent integration of information. Left: When walking down \DIFdelbeginFL  {\color {red}\sout {a }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {an unfamiliar }}\DIFaddendFL  staircase that is \DIFdelbeginFL  {\color {red}\sout {clearly }}\DIFdelendFL  visible, the brain might rely solely on external sensory information. Middle: When walking down the same stairs \DIFdelbeginFL  {\color {red}\sout {in the absence of }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {without }}\DIFaddendFL  visual information, the brain might rely on predictions formed by previous experience. Right: When climbing down an unexplored mountain in foggy conditions, the brain might need to integrate sensory information and predictions \DIFdelbeginFL  {\color {red}\sout {at the same time}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {simultaneously}}\DIFaddendFL  . {\bf  (B)} Illustration of a prediction-error (PE) circuit with both negative and positive PE (nPE/pPE) neurons that receive inhibition from three different inhibitory interneuron types: parvalbumin-expressing (PV), somatostatin-expressing (SOM), and vasoactive intestinal peptide-expressing (VIP) interneurons. Local excitatory connections are not shown for clarity. {\bf  (C)} Illustration of network model that estimates the mean and variance of the external sensory stimuli. The core of this network model is the PE circuit shown in (B). The lower-level V neuron encodes the variance, while the lower-level M neuron encodes the mean of the sensory input. {\bf  (D)} Same as in (C) but the feedforward input is the activity of the lower-level M neuron. \relax }}{3}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:Fig_1}{{1}{3}{\DIFdelbeginFL \DIFdelendFL \DIFaddbeginFL \footnotesize {\bf Neural network model to track both the uncertainty of sensory inputs and predictions.\newline } \DIFaddendFL {\bf (A)} Example illustration \DIFdelbeginFL \DIFdelFL {of }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {for }\DIFaddendFL context-dependent integration of information. Left: When walking down \DIFdelbeginFL \DIFdelFL {a }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {an unfamiliar }\DIFaddendFL staircase that is \DIFdelbeginFL \DIFdelFL {clearly }\DIFdelendFL visible, the brain might rely solely on external sensory information. Middle: When walking down the same stairs \DIFdelbeginFL \DIFdelFL {in the absence of }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {without }\DIFaddendFL visual information, the brain might rely on predictions formed by previous experience. Right: When climbing down an unexplored mountain in foggy conditions, the brain might need to integrate sensory information and predictions \DIFdelbeginFL \DIFdelFL {at the same time}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {simultaneously}\DIFaddendFL . {\bf (B)} Illustration of a prediction-error (PE) circuit with both negative and positive PE (nPE/pPE) neurons that receive inhibition from three different inhibitory interneuron types: parvalbumin-expressing (PV), somatostatin-expressing (SOM), and vasoactive intestinal peptide-expressing (VIP) interneurons. Local excitatory connections are not shown for clarity. {\bf (C)} Illustration of network model that estimates the mean and variance of the external sensory stimuli. The core of this network model is the PE circuit shown in (B). The lower-level V neuron encodes the variance, while the lower-level M neuron encodes the mean of the sensory input. {\bf (D)} Same as in (C) but the feedforward input is the activity of the lower-level M neuron. \relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \DIFdelbeginFL  \DIFdelendFL  \DIFaddbeginFL  \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  Prediction-error neurons as the basis for estimating mean and variance of sensory stimuli.\newline  } \DIFaddendFL  {\bf  (A)} Illustration of the inputs with which the network \DIFdelbeginFL  {\color {red}\sout {shown in }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {(Fig. }}\DIFaddendFL  \ref  {fig:Fig_1}C\DIFaddbeginFL  {\color {blue}\uwave {) }}\DIFaddendFL  is stimulated. Network is exposed to a sequence of constant stimuli drawn from a uniform distribution. \DIFdelbeginFL  {\color {red}\sout {Stimulus duration is XXX. }}\DIFdelendFL  {\bf  (B)} PE neuron activity hardly changes with stimulus strength (left) but strongly increases with stimulus variability (right). {\bf  (C)} Interneuron activity strongly changes with stimulus strength (left) but hardly changes with stimulus variability (right). {\bf  (D)} M neuron correctly encodes the mean of the sensory stimuli. Left: Illustration of the input synapses onto the M neuron. Middle: Activity of the M neuron over time for \DIFdelbeginFL  {\color {red}\sout {a uniform }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {one example }}\DIFaddendFL  distribution \DIFdelbeginFL  {\color {red}\sout {with mean XXX and standard deviation XXX}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {(black start in right panel)}}\DIFaddendFL  . Right: Normalised \DIFdelbeginFL  {\color {red}\sout {mean-squared error (MSE) }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {absolute difference }}\DIFaddendFL  between the \DIFdelbeginFL  {\color {red}\sout {running average }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {averaged mean }}\DIFaddendFL  and the \DIFaddbeginFL  {\color {blue}\uwave {activity of the }}\DIFaddendFL  M neuron \DIFdelbeginFL  {\color {red}\sout {activity }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {in the steady state }}\DIFaddendFL  for different parametrizations of the stimulus distribution. {\bf  (E)} V neuron correctly encodes the variance of the sensory stimuli. Left: Illustration of the input synapses onto the V neuron. Middle: Activity of the V neuron over time for \DIFdelbeginFL  {\color {red}\sout {a uniform }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {one example }}\DIFaddendFL  distribution \DIFdelbeginFL  {\color {red}\sout {with mean XXX and standard deviation XXX}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {(black start in right panel)}}\DIFaddendFL  . Right: Normalised \DIFdelbeginFL  {\color {red}\sout {mean-squared error (MSE) }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {absolute difference }}\DIFaddendFL  between the \DIFdelbeginFL  {\color {red}\sout {instantaneous }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {averaged }}\DIFaddendFL  variance and the \DIFaddbeginFL  {\color {blue}\uwave {activity of the }}\DIFaddendFL  V neuron \DIFdelbeginFL  {\color {red}\sout {activity }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {in the steady state }}\DIFaddendFL  for different parametrizations of the stimulus distribution. \relax }}{4}{figure.caption.5}}
\newlabel{fig:Fig_2}{{2}{4}{\DIFdelbeginFL \DIFdelendFL \DIFaddbeginFL \footnotesize {\bf Prediction-error neurons as the basis for estimating mean and variance of sensory stimuli.\newline } \DIFaddendFL {\bf (A)} Illustration of the inputs with which the network \DIFdelbeginFL \DIFdelFL {shown in }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {(Fig. }\DIFaddendFL \ref {fig:Fig_1}C\DIFaddbeginFL \DIFaddFL {) }\DIFaddendFL is stimulated. Network is exposed to a sequence of constant stimuli drawn from a uniform distribution. \DIFdelbeginFL \DIFdelFL {Stimulus duration is XXX. }\DIFdelendFL {\bf (B)} PE neuron activity hardly changes with stimulus strength (left) but strongly increases with stimulus variability (right). {\bf (C)} Interneuron activity strongly changes with stimulus strength (left) but hardly changes with stimulus variability (right). {\bf (D)} M neuron correctly encodes the mean of the sensory stimuli. Left: Illustration of the input synapses onto the M neuron. Middle: Activity of the M neuron over time for \DIFdelbeginFL \DIFdelFL {a uniform }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {one example }\DIFaddendFL distribution \DIFdelbeginFL \DIFdelFL {with mean XXX and standard deviation XXX}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {(black start in right panel)}\DIFaddendFL . Right: Normalised \DIFdelbeginFL \DIFdelFL {mean-squared error (MSE) }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {absolute difference }\DIFaddendFL between the \DIFdelbeginFL \DIFdelFL {running average }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {averaged mean }\DIFaddendFL and the \DIFaddbeginFL \DIFaddFL {activity of the }\DIFaddendFL M neuron \DIFdelbeginFL \DIFdelFL {activity }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {in the steady state }\DIFaddendFL for different parametrizations of the stimulus distribution. {\bf (E)} V neuron correctly encodes the variance of the sensory stimuli. Left: Illustration of the input synapses onto the V neuron. Middle: Activity of the V neuron over time for \DIFdelbeginFL \DIFdelFL {a uniform }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {one example }\DIFaddendFL distribution \DIFdelbeginFL \DIFdelFL {with mean XXX and standard deviation XXX}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {(black start in right panel)}\DIFaddendFL . Right: Normalised \DIFdelbeginFL \DIFdelFL {mean-squared error (MSE) }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {absolute difference }\DIFaddendFL between the \DIFdelbeginFL \DIFdelFL {instantaneous }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {averaged }\DIFaddendFL variance and the \DIFaddbeginFL \DIFaddFL {activity of the }\DIFaddendFL V neuron \DIFdelbeginFL \DIFdelFL {activity }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {in the steady state }\DIFaddendFL for different parametrizations of the stimulus distribution. \relax }{figure.caption.5}{}}
\citation{pouget2013probabilistic}
\citation{yon2021precision}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \DIFdelbeginFL  \DIFdelendFL  \DIFaddbeginFL  \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  Estimating the uncertainty of both the sensory input and the prediction.\newline  } \DIFaddendFL  {\bf  (A)} Illustration of the stimulation protocol. \DIFdelbeginFL  {\color {red}\sout {Network }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {The network }}\DIFaddendFL  is exposed to a sequence of stimuli (one stimulus per trial). To account for stimulus variability, each stimulus is represented by \DIFdelbeginFL  {\color {red}\sout {xxx }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {$10$ }}\DIFaddendFL  stimulus values drawn from a normal distribution\DIFdelbeginFL  {\color {red}\sout {with mean $\mu _\mathrm  {stim}$ and $\sigma _\mathrm  {stim}^2$}}\DIFdelendFL  . To account for the volatility of the environment, in each trial\DIFaddbeginFL  {\color {blue}\uwave {, }}\DIFaddendFL  the stimulus mean \DIFdelbeginFL  {\color {red}\sout {$\mu _\mathrm  {stim}$ }}\DIFdelendFL  is drawn from a uniform distribution (denoted trial variability). \DIFdelbeginFL  {\color {red}\sout {Trial duration = xxx. }}\DIFdelendFL  {\bf  (B)} \DIFdelbeginFL  {\color {red}\sout {Neuron activity increases with both stimulus and trial variability. Neurons in }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {Illustration of how }}\DIFaddendFL  the \DIFdelbeginFL  {\color {red}\sout {lower PE circuit increase more strongly with stimulus variability}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {weighted output is calculated}}\DIFaddendFL  . \DIFdelbeginFL  {\color {red}\sout {Neurons in }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {The sensory weight $\alpha $ lies between zero (system relies perfectly on prediction) and one (system relies solely on }}\DIFaddendFL  the \DIFdelbeginFL  {\color {red}\sout {higher PE circuit increase more strongly with trial variability}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {sensory input)}}\DIFaddendFL  . {\bf  (C)} Limit case example in which the stimulus variability is \DIFdelbeginFL  {\color {red}\sout {low }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {zero }}\DIFaddendFL  but the trial variability is high. Left: Illustration of the stimulation protocol. Middle: Weighted output follows closely the sensory stimuli. Right: Sensory weight (function of the variances, see \DIFdelbeginFL  {\color {red}\sout {text}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {B}}\DIFaddendFL  ) close to 1, indicating that the network ignores the prediction. Input statistics \DIFdelbeginFL  {\color {red}\sout {: XXX}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {shown in E}}\DIFaddendFL  . {\bf  (D)} Limit case example in which the stimulus variability is high but the trial variability is \DIFdelbeginFL  {\color {red}\sout {low}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {zero}}\DIFaddendFL  . Left: Illustration of the stimulation protocol. Middle: Weighted output pushed towards the mean of the sensory stimuli. Right: Sensory weight close to zero, indicating that the network ignores the sensory stimuli. Input statistics \DIFdelbeginFL  {\color {red}\sout {: XXX}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {shown in E}}\DIFaddendFL  . {\bf  (E)} \DIFaddbeginFL  {\color {blue}\uwave {Sensory weight for different input statistics. }}\DIFaddendFL  Predictions are weighted more strongly when the stimulus variability is larger than the trial variability. {\bf  (F)} \DIFaddbeginFL  {\color {blue}\uwave {Sensory weight throughout a trial for two different trial durations. }}\DIFaddendFL  Predictions are weighted more strongly at the beginning of a new trial\DIFdelbeginFL  {\color {red}\sout {and quickly changing stimuli}}\DIFdelendFL  . \relax }}{6}{figure.caption.7}}
\newlabel{fig:Fig_3}{{3}{6}{\DIFdelbeginFL \DIFdelendFL \DIFaddbeginFL \footnotesize {\bf Estimating the uncertainty of both the sensory input and the prediction.\newline } \DIFaddendFL {\bf (A)} Illustration of the stimulation protocol. \DIFdelbeginFL \DIFdelFL {Network }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {The network }\DIFaddendFL is exposed to a sequence of stimuli (one stimulus per trial). To account for stimulus variability, each stimulus is represented by \DIFdelbeginFL \DIFdelFL {xxx }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {$10$ }\DIFaddendFL stimulus values drawn from a normal distribution\DIFdelbeginFL \DIFdelFL {with mean $\mu _\mathrm {stim}$ and $\sigma _\mathrm {stim}^2$}\DIFdelendFL . To account for the volatility of the environment, in each trial\DIFaddbeginFL \DIFaddFL {, }\DIFaddendFL the stimulus mean \DIFdelbeginFL \DIFdelFL {$\mu _\mathrm {stim}$ }\DIFdelendFL is drawn from a uniform distribution (denoted trial variability). \DIFdelbeginFL \DIFdelFL {Trial duration = xxx. }\DIFdelendFL {\bf (B)} \DIFdelbeginFL \DIFdelFL {Neuron activity increases with both stimulus and trial variability. Neurons in }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {Illustration of how }\DIFaddendFL the \DIFdelbeginFL \DIFdelFL {lower PE circuit increase more strongly with stimulus variability}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {weighted output is calculated}\DIFaddendFL . \DIFdelbeginFL \DIFdelFL {Neurons in }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {The sensory weight $\alpha $ lies between zero (system relies perfectly on prediction) and one (system relies solely on }\DIFaddendFL the \DIFdelbeginFL \DIFdelFL {higher PE circuit increase more strongly with trial variability}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {sensory input)}\DIFaddendFL . {\bf (C)} Limit case example in which the stimulus variability is \DIFdelbeginFL \DIFdelFL {low }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {zero }\DIFaddendFL but the trial variability is high. Left: Illustration of the stimulation protocol. Middle: Weighted output follows closely the sensory stimuli. Right: Sensory weight (function of the variances, see \DIFdelbeginFL \DIFdelFL {text}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {B}\DIFaddendFL ) close to 1, indicating that the network ignores the prediction. Input statistics \DIFdelbeginFL \DIFdelFL {: XXX}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {shown in E}\DIFaddendFL . {\bf (D)} Limit case example in which the stimulus variability is high but the trial variability is \DIFdelbeginFL \DIFdelFL {low}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {zero}\DIFaddendFL . Left: Illustration of the stimulation protocol. Middle: Weighted output pushed towards the mean of the sensory stimuli. Right: Sensory weight close to zero, indicating that the network ignores the sensory stimuli. Input statistics \DIFdelbeginFL \DIFdelFL {: XXX}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {shown in E}\DIFaddendFL . {\bf (E)} \DIFaddbeginFL \DIFaddFL {Sensory weight for different input statistics. }\DIFaddendFL Predictions are weighted more strongly when the stimulus variability is larger than the trial variability. {\bf (F)} \DIFaddbeginFL \DIFaddFL {Sensory weight throughout a trial for two different trial durations. }\DIFaddendFL Predictions are weighted more strongly at the beginning of a new trial\DIFdelbeginFL \DIFdelFL {and quickly changing stimuli}\DIFdelendFL . \relax }{figure.caption.7}{}}
\citation{avery2017neuromodulatory}
\citation{cardin2019functional,hattori2017functions,swanson2019hiring}
\citation{wester2014behavioral,hattori2017functions,swanson2019hiring}
\citation{hertag2022prediction}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  Neuromodulator-based shifts in the weighting of sensory inputs and predictions. \newline  } {\bf  (A)} Neuromodulators acting on the \DIFdelbeginFL  {\color {red}\sout {three }}\DIFdelendFL  interneurons \DIFdelbeginFL  {\color {red}\sout {may }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {can }}\DIFaddendFL  shift the weighting of sensory inputs and predictions. The changes depend on the type \DIFdelbeginFL  {\color {red}\sout {/s }}\DIFdelendFL  of \DIFdelbeginFL  {\color {red}\sout {interneurons }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {interneuron }}\DIFaddendFL  targeted \DIFdelbeginFL  {\color {red}\sout {by }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {and }}\DIFaddendFL  the \DIFaddbeginFL  {\color {blue}\uwave {modulation strength (here simulated through an }}\DIFaddendFL  additional excitatory input\DIFdelbeginFL  {\color {red}\sout {emulating a neuromodulator (additional input = XXX}}\DIFdelendFL  ). Considered are two limit cases (upper row: more sensory-driven before modulation, lower row: more prediction-driven before modulation). The \DIFdelbeginFL  {\color {red}\sout {combination of interneurons targeted is illustrated below. The }}\DIFdelendFL  results are shown for three different PE circuits \DIFdelbeginFL  {\color {red}\sout {, specified in the main text}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {(denotes by different markers)}}\DIFaddendFL  . {\bf  (B)} \DIFdelbeginFL  {\color {red}\sout {Illustration showing how }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {When SOM and VIP neurons are equally modulated, }}\DIFaddendFL  the sensory weight \DIFdelbeginFL  {\color {red}\sout {depends on changes in both the stimulus and trial variability}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {remains unaffected}}\DIFaddendFL  . {\bf  (C)} The \DIFdelbeginFL  {\color {red}\sout {M and }}\DIFdelendFL  V \DIFdelbeginFL  {\color {red}\sout {neuron }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {neurons' }}\DIFaddendFL  activities depend on the PE \DIFdelbeginFL  {\color {red}\sout {neuron activities}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {neurons}}\DIFaddendFL  . Hence, perturbing the nPE and pPE neurons \DIFdelbeginFL  {\color {red}\sout {must change }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {changes }}\DIFaddendFL  the \DIFaddbeginFL  {\color {blue}\uwave {uncertainty }}\DIFaddendFL  estimation\DIFdelbeginFL  {\color {red}\sout {of mean and variance}}\DIFdelendFL  . While stimulating the lower PE neurons affects both the lower and \DIFdelbeginFL  {\color {red}\sout {higher mean and variance estimation}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {higher-order V neurons (right)}}\DIFaddendFL  , stimulating the \DIFdelbeginFL  {\color {red}\sout {higher }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {higher-order }}\DIFaddendFL  PE neurons only affects the V \DIFdelbeginFL  {\color {red}\sout {and M neurons }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {neuron }}\DIFaddendFL  in the same subnetwork \DIFaddbeginFL  {\color {blue}\uwave {(left)}}\DIFaddendFL  . {\bf  (D)} \DIFdelbeginFL  {\color {red}\sout {Illustration of }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {The V neuron activity, and hence }}\DIFaddendFL  the \DIFdelbeginFL  {\color {red}\sout {mechanisms underlying the biased estimation }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {sensory weight, changes as a result }}\DIFaddendFL  of \DIFdelbeginFL  {\color {red}\sout {mean and variance when }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {the modulated }}\DIFaddendFL  PE \DIFdelbeginFL  {\color {red}\sout {neurons are perturbed}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {neuron activity}}\DIFaddendFL  . \DIFdelbeginFL  {\color {red}\sout {Both }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {The PE neuron activity, on the other hand, }}\DIFaddendFL  changes \DIFdelbeginFL  {\color {red}\sout {in }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {as a result of }}\DIFaddendFL  the \DIFaddbeginFL  {\color {blue}\uwave {interneurons being modulated. The interneurons change the }}\DIFaddendFL  baseline (left) and \DIFaddbeginFL  {\color {blue}\uwave {the }}\DIFaddendFL  gain (right) of \DIFdelbeginFL  {\color {red}\sout {PE neurons can contribute to }}\DIFdelendFL  the \DIFdelbeginFL  {\color {red}\sout {changes observed in (C). Illustration based on toy model described in Methods. }}{\color {red}\sout {(E)}}{\color {red}\sout {Modulated interneurons change the weighting by changing the overall baseline and the overall gain of }}\DIFdelendFL  PE neurons\DIFdelbeginFL  {\color {red}\sout {(sum of changes in nPE and pPE neurons)}}\DIFdelendFL  . Whether \DIFdelbeginFL  {\color {red}\sout {and how a neuromodulator changes }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {an interneuron increases or decreases }}\DIFaddendFL  the \DIFdelbeginFL  {\color {red}\sout {sensory weight, hence, }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {estimated variance }}\DIFaddendFL  depends on \DIFdelbeginFL  {\color {red}\sout {the interneuron targeted and the effect this interneuron has on baseline and gain of the PE neurons, which in turn does depend on the network it is embedded in}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {both factors}}\DIFaddendFL  . \relax }}{8}{figure.caption.9}}
\newlabel{fig:Fig_4}{{4}{8}{\footnotesize {\bf Neuromodulator-based shifts in the weighting of sensory inputs and predictions. \newline } {\bf (A)} Neuromodulators acting on the \DIFdelbeginFL \DIFdelFL {three }\DIFdelendFL interneurons \DIFdelbeginFL \DIFdelFL {may }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {can }\DIFaddendFL shift the weighting of sensory inputs and predictions. The changes depend on the type \DIFdelbeginFL \DIFdelFL {/s }\DIFdelendFL of \DIFdelbeginFL \DIFdelFL {interneurons }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {interneuron }\DIFaddendFL targeted \DIFdelbeginFL \DIFdelFL {by }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {and }\DIFaddendFL the \DIFaddbeginFL \DIFaddFL {modulation strength (here simulated through an }\DIFaddendFL additional excitatory input\DIFdelbeginFL \DIFdelFL {emulating a neuromodulator (additional input = XXX}\DIFdelendFL ). Considered are two limit cases (upper row: more sensory-driven before modulation, lower row: more prediction-driven before modulation). The \DIFdelbeginFL \DIFdelFL {combination of interneurons targeted is illustrated below. The }\DIFdelendFL results are shown for three different PE circuits \DIFdelbeginFL \DIFdelFL {, specified in the main text}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {(denotes by different markers)}\DIFaddendFL . {\bf (B)} \DIFdelbeginFL \DIFdelFL {Illustration showing how }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {When SOM and VIP neurons are equally modulated, }\DIFaddendFL the sensory weight \DIFdelbeginFL \DIFdelFL {depends on changes in both the stimulus and trial variability}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {remains unaffected}\DIFaddendFL . {\bf (C)} The \DIFdelbeginFL \DIFdelFL {M and }\DIFdelendFL V \DIFdelbeginFL \DIFdelFL {neuron }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {neurons' }\DIFaddendFL activities depend on the PE \DIFdelbeginFL \DIFdelFL {neuron activities}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {neurons}\DIFaddendFL . Hence, perturbing the nPE and pPE neurons \DIFdelbeginFL \DIFdelFL {must change }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {changes }\DIFaddendFL the \DIFaddbeginFL \DIFaddFL {uncertainty }\DIFaddendFL estimation\DIFdelbeginFL \DIFdelFL {of mean and variance}\DIFdelendFL . While stimulating the lower PE neurons affects both the lower and \DIFdelbeginFL \DIFdelFL {higher mean and variance estimation}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {higher-order V neurons (right)}\DIFaddendFL , stimulating the \DIFdelbeginFL \DIFdelFL {higher }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {higher-order }\DIFaddendFL PE neurons only affects the V \DIFdelbeginFL \DIFdelFL {and M neurons }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {neuron }\DIFaddendFL in the same subnetwork \DIFaddbeginFL \DIFaddFL {(left)}\DIFaddendFL . {\bf (D)} \DIFdelbeginFL \DIFdelFL {Illustration of }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {The V neuron activity, and hence }\DIFaddendFL the \DIFdelbeginFL \DIFdelFL {mechanisms underlying the biased estimation }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {sensory weight, changes as a result }\DIFaddendFL of \DIFdelbeginFL \DIFdelFL {mean and variance when }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {the modulated }\DIFaddendFL PE \DIFdelbeginFL \DIFdelFL {neurons are perturbed}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {neuron activity}\DIFaddendFL . \DIFdelbeginFL \DIFdelFL {Both }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {The PE neuron activity, on the other hand, }\DIFaddendFL changes \DIFdelbeginFL \DIFdelFL {in }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {as a result of }\DIFaddendFL the \DIFaddbeginFL \DIFaddFL {interneurons being modulated. The interneurons change the }\DIFaddendFL baseline (left) and \DIFaddbeginFL \DIFaddFL {the }\DIFaddendFL gain (right) of \DIFdelbeginFL \DIFdelFL {PE neurons can contribute to }\DIFdelendFL the \DIFdelbeginFL \DIFdelFL {changes observed in (C). Illustration based on toy model described in Methods. }\DIFdelFL {(E)}\DIFdelFL {Modulated interneurons change the weighting by changing the overall baseline and the overall gain of }\DIFdelendFL PE neurons\DIFdelbeginFL \DIFdelFL {(sum of changes in nPE and pPE neurons)}\DIFdelendFL . Whether \DIFdelbeginFL \DIFdelFL {and how a neuromodulator changes }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {an interneuron increases or decreases }\DIFaddendFL the \DIFdelbeginFL \DIFdelFL {sensory weight, hence, }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {estimated variance }\DIFaddendFL depends on \DIFdelbeginFL \DIFdelFL {the interneuron targeted and the effect this interneuron has on baseline and gain of the PE neurons, which in turn does depend on the network it is embedded in}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {both factors}\DIFaddendFL . \relax }{figure.caption.9}{}}
\citation{hollingworth1910central,jazayeri2010temporal,ashourian2011bayesian,petzschner2011iterative,akrami2018posterior,meirhaeghe2021precise}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  Mechanisms underlying the contraction bias.\newline  } {\bf  (A)} \DIFdelbeginFL  {\color {red}\sout {Illustration of the contraction }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {Contraction }}\DIFaddendFL  bias \DIFaddbeginFL  {\color {blue}\uwave {in the model for two different stimulus uncertainties depicted in the inset}}\DIFaddendFL  . \DIFdelbeginFL  {\color {red}\sout {The estimated input }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {Bias }}\DIFaddendFL  is \DIFdelbeginFL  {\color {red}\sout {shifted towards }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {defined as }}\DIFaddendFL  the \DIFaddbeginFL  {\color {blue}\uwave {weighted output minus the stimulus }}\DIFaddendFL  mean\DIFaddbeginFL  {\color {blue}\uwave {. The absolute value }}\DIFaddendFL  of the \DIFdelbeginFL  {\color {red}\sout {input distribution. Hence, a linear curve fitted to the data has a }}\DIFdelendFL  slope \DIFdelbeginFL  {\color {red}\sout {below 1 }}\DIFdelendFL  (\DIFdelbeginFL  {\color {red}\sout {left}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {see linear fit}}\DIFaddendFL  ) \DIFaddbeginFL  {\color {blue}\uwave {is a measure of the bias}}\DIFaddendFL  . The \DIFdelbeginFL  {\color {red}\sout {bias is biggest at }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {larger }}\DIFaddendFL  the \DIFdelbeginFL  {\color {red}\sout {end of }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {slope, }}\DIFaddendFL  the \DIFdelbeginFL  {\color {red}\sout {stimulus distribution (right)}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {larger the bias}}\DIFaddendFL  . {\bf  (B)} \DIFdelbeginFL  {\color {red}\sout {Contraction bias in the model. Left: Example for two different stimulus variabilities. Right: }}\DIFdelendFL  As a consequence of the sensory weight, the slope \DIFdelbeginFL  {\color {red}\sout {decreases }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {increases }}\DIFaddendFL  with stimulus variability (bias increases) and \DIFdelbeginFL  {\color {red}\sout {increases }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {decreases }}\DIFaddendFL  with trial variability (bias decreases). \DIFdelbeginFL  {\color {red}\sout {Stimulus statistics: XXX. }}\DIFdelendFL  {\bf  (C)} \DIFdelbeginFL  {\color {red}\sout {The bias }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {Bias }}\DIFaddendFL  is independent of \DIFaddbeginFL  {\color {blue}\uwave {the }}\DIFaddendFL  trial variability when the stimulus variability is zero\DIFaddbeginFL  {\color {blue}\uwave {. }}{\bf  \DIFaddendFL  (\DIFdelbeginFL  {\color {red}\sout {left}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {D}}\DIFaddendFL  )\DIFdelbeginFL  {\color {red}\sout {. Equally, the bias }}\DIFdelendFL  \DIFaddbeginFL  } {\color {blue}\uwave {Bias }}\DIFaddendFL  is independent of the stimulus variability when the trial variability is zero\DIFdelbeginFL  {\color {red}\sout {(right)}}\DIFdelendFL  . \DIFdelbeginFL  {\color {red}\sout {Stimulus statistics: XXX. }}\DIFdelendFL  {\bf  (\DIFdelbeginFL  {\color {red}\sout {D}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {E}}\DIFaddendFL  )} The slope depends on the trial duration. \DIFdelbeginFL  {\color {red}\sout {If the sensory weight is 1, the slope is independent of the trail duration and the bias vanishes (dashed-dotted line). If the sensory weight is 0, the slope depends on the trial duration and only reaches 1 if the trial duration approaches infinity. }}{\color {red}\sout {(E)}}{\color {red}\sout {To ensure a larger bias for stimuli drawn from the upper end of the stimulus distribution than from the lower end, scalar variability as observed experimentally is needed. }}\DIFdelendFL  \relax }}{10}{figure.caption.11}}
\newlabel{fig:Fig_5}{{5}{10}{\footnotesize {\bf Mechanisms underlying the contraction bias.\newline } {\bf (A)} \DIFdelbeginFL \DIFdelFL {Illustration of the contraction }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {Contraction }\DIFaddendFL bias \DIFaddbeginFL \DIFaddFL {in the model for two different stimulus uncertainties depicted in the inset}\DIFaddendFL . \DIFdelbeginFL \DIFdelFL {The estimated input }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {Bias }\DIFaddendFL is \DIFdelbeginFL \DIFdelFL {shifted towards }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {defined as }\DIFaddendFL the \DIFaddbeginFL \DIFaddFL {weighted output minus the stimulus }\DIFaddendFL mean\DIFaddbeginFL \DIFaddFL {. The absolute value }\DIFaddendFL of the \DIFdelbeginFL \DIFdelFL {input distribution. Hence, a linear curve fitted to the data has a }\DIFdelendFL slope \DIFdelbeginFL \DIFdelFL {below 1 }\DIFdelendFL (\DIFdelbeginFL \DIFdelFL {left}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {see linear fit}\DIFaddendFL ) \DIFaddbeginFL \DIFaddFL {is a measure of the bias}\DIFaddendFL . The \DIFdelbeginFL \DIFdelFL {bias is biggest at }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {larger }\DIFaddendFL the \DIFdelbeginFL \DIFdelFL {end of }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {slope, }\DIFaddendFL the \DIFdelbeginFL \DIFdelFL {stimulus distribution (right)}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {larger the bias}\DIFaddendFL . {\bf (B)} \DIFdelbeginFL \DIFdelFL {Contraction bias in the model. Left: Example for two different stimulus variabilities. Right: }\DIFdelendFL As a consequence of the sensory weight, the slope \DIFdelbeginFL \DIFdelFL {decreases }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {increases }\DIFaddendFL with stimulus variability (bias increases) and \DIFdelbeginFL \DIFdelFL {increases }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {decreases }\DIFaddendFL with trial variability (bias decreases). \DIFdelbeginFL \DIFdelFL {Stimulus statistics: XXX. }\DIFdelendFL {\bf (C)} \DIFdelbeginFL \DIFdelFL {The bias }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {Bias }\DIFaddendFL is independent of \DIFaddbeginFL \DIFaddFL {the }\DIFaddendFL trial variability when the stimulus variability is zero\DIFaddbeginFL \DIFaddFL {. }{\bf \DIFaddendFL (\DIFdelbeginFL \DIFdelFL {left}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {D}\DIFaddendFL )\DIFdelbeginFL \DIFdelFL {. Equally, the bias }\DIFdelendFL \DIFaddbeginFL } \DIFaddFL {Bias }\DIFaddendFL is independent of the stimulus variability when the trial variability is zero\DIFdelbeginFL \DIFdelFL {(right)}\DIFdelendFL . \DIFdelbeginFL \DIFdelFL {Stimulus statistics: XXX. }\DIFdelendFL {\bf (\DIFdelbeginFL \DIFdelFL {D}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {E}\DIFaddendFL )} The slope depends on the trial duration. \DIFdelbeginFL \DIFdelFL {If the sensory weight is 1, the slope is independent of the trail duration and the bias vanishes (dashed-dotted line). If the sensory weight is 0, the slope depends on the trial duration and only reaches 1 if the trial duration approaches infinity. }\DIFdelFL {(E)}\DIFdelFL {To ensure a larger bias for stimuli drawn from the upper end of the stimulus distribution than from the lower end, scalar variability as observed experimentally is needed. }\DIFdelendFL \relax }{figure.caption.11}{}}
\citation{rakitin1998scalar}
\citation{han2023behavior}
\citation{kording2004bayesian,yon2021precision}
\citation{ernst2002humans}
\citation{battaglia2003bayesian,kording2004bayesian,alais2004ventriloquist,rowland2007bayesian,gu2008neural,fetsch2012neural}
\citation{wallace1998multisensory,gu2008neural,fetsch2012neural}
\citation{kording2004bayesian,yon2021precision}
\citation{pakan2018impact,han2023behavior}
\citation{yon2021precision}
\citation{herzfeld2014memory}
\citation{yon2021precision}
\citation{cardin2019functional}
\citation{o2010coding,o2012can}
\citation{knill2004bayesian}
\citation{hoyer2002interpreting,ma2006bayesian}
\citation{soltani2019adaptive}
\citation{kiani2009representation}
\citation{masset2020behavior}
\citation{rushworth2008choice}
\citation{jo2016differential}
\citation{white2016neurons}
\citation{rutishauser2015representation,rutishauser2018single}
\citation{bastos2012canonical,keller2018predictive}
\citation{bastos2012canonical,heindorf2022reduction}
\citation{o2022prediction}
\citation{eliades2008neural,keller2009neural,ayaz2019layer,audette2021temporally}
\citation{rao1999predictive}
\citation{keller2012sensorimotor,attinger2017visuomotor,jordan2020opposing,audette2021temporally}
\citation{keller2018predictive}
\citation{murray2014hierarchy,chaudhuri2015large,runyan2017distinct}
\citation{yon2021precision}
\citation{yon2021precision}
\citation{yon2021precision}
\citation{yu2005uncertainty}
\citation{yu2005uncertainty}
\citation{hasselmo1997noradrenergic,yon2021precision}
\citation{ridley1981new,janitzky2015optogenetic}
\citation{lawson2021computational}
\citation{yon2021precision}
\citation{urban2016somatostatin,hattori2017functions,swanson2019hiring}
\citation{nadim2014neuromodulation}
\citation{yu2005uncertainty,marshall2016pharmacological}
\citation{marshall2016pharmacological}
\citation{wester2014behavioral,hattori2017functions,swanson2019hiring}
\citation{pawlak2010timing}
\citation{jordan2023locus}
\citation{jordan2023locus}
\citation{wilmes2023uncertainty}
\citation{marshall2016pharmacological,bruckner2022understanding}
\citation{wong2023computational}
\citation{battaglia2003bayesian,alais2004ventriloquist}
\citation{butler2010bayesian}
\citation{fetsch2009dynamic}
\citation{summerfield2011perceptual}
\citation{o2012can}
\citation{soltani2019adaptive}
\citation{liakoni2021learning}
\citation{kutschireiter2023bayesian}
\citation{deneve2008bayesian}
\citation{pouget2013probabilistic}
\bibstyle{plainnat}
\bibdata{References_HertaegWilmesClopath_2023}
\bibcite{akrami2018posterior}{{1}{2018}{{Akrami et~al.}}{{Akrami, Kopec, Diamond, and Brody}}}
\bibcite{alais2004ventriloquist}{{2}{2004}{{Alais and Burr}}{{}}}
\bibcite{ashourian2011bayesian}{{3}{2011}{{Ashourian and Loewenstein}}{{}}}
\bibcite{attinger2017visuomotor}{{4}{2017}{{Attinger et~al.}}{{Attinger, Wang, and Keller}}}
\bibcite{audette2021temporally}{{5}{2021}{{Audette et~al.}}{{Audette, Zhou, and Schneider}}}
\bibcite{avery2017neuromodulatory}{{6}{2017}{{Avery and Krichmar}}{{}}}
\bibcite{ayaz2019layer}{{7}{2019}{{Ayaz et~al.}}{{Ayaz, St{\"a}uble, Hamada, Wulf, Saleem, and Helmchen}}}
\bibcite{bastos2012canonical}{{8}{2012}{{Bastos et~al.}}{{Bastos, Usrey, Adams, Mangun, Fries, and Friston}}}
\bibcite{battaglia2003bayesian}{{9}{2003}{{Battaglia et~al.}}{{Battaglia, Jacobs, and Aslin}}}
\bibcite{bruckner2022understanding}{{10}{2022}{{Bruckner et~al.}}{{Bruckner, Heekeren, and Nassar}}}
\bibcite{butler2010bayesian}{{11}{2010}{{Butler et~al.}}{{Butler, Smith, Campos, and B{\"u}lthoff}}}
\bibcite{campagnola2022local}{{12}{2022}{{Campagnola et~al.}}{{Campagnola, Seeman, Chartrand, Kim, Hoggarth, Gamlin, Ito, Trinh, Davoudian, Radaelli, et~al.}}}
\bibcite{cardin2019functional}{{13}{2019}{{Cardin}}{{}}}
\bibcite{chaudhuri2015large}{{14}{2015}{{Chaudhuri et~al.}}{{Chaudhuri, Knoblauch, Gariel, Kennedy, and Wang}}}
\bibcite{deneve2008bayesian}{{15}{2008}{{Deneve}}{{}}}
\bibcite{deneve2004bayesian}{{16}{2004}{{Deneve and Pouget}}{{}}}
\bibcite{eliades2008neural}{{17}{2008}{{Eliades and Wang}}{{}}}
\bibcite{ernst2002humans}{{18}{2002}{{Ernst and Banks}}{{}}}
\bibcite{fetsch2009dynamic}{{19}{2009}{{Fetsch et~al.}}{{Fetsch, Turner, DeAngelis, and Angelaki}}}
\bibcite{fetsch2012neural}{{20}{2012}{{Fetsch et~al.}}{{Fetsch, Pouget, DeAngelis, and Angelaki}}}
\bibcite{friston2008hierarchical}{{21}{2008}{{Friston}}{{}}}
\bibcite{gu2008neural}{{22}{2008}{{Gu et~al.}}{{Gu, Angelaki, and DeAngelis}}}
\bibcite{han2023behavior}{{23}{2023}{{Han and Helmchen}}{{}}}
\bibcite{harris2015neocortical}{{24}{2015}{{Harris and Shepherd}}{{}}}
\bibcite{hasselmo1997noradrenergic}{{25}{1997}{{Hasselmo et~al.}}{{Hasselmo, Linster, Patil, Ma, and Cekic}}}
\bibcite{hattori2017functions}{{26}{2017}{{Hattori et~al.}}{{Hattori, Kuchibhotla, Froemke, and Komiyama}}}
\bibcite{heindorf2022reduction}{{27}{2022}{{Heindorf and Keller}}{{}}}
\bibcite{hertag2022prediction}{{28}{2022}{{Hert{\"a}g and Clopath}}{{}}}
\bibcite{hertag2020learning}{{29}{2020}{{Hert{\"a}g and Sprekeler}}{{}}}
\bibcite{herzfeld2014memory}{{30}{2014}{{Herzfeld et~al.}}{{Herzfeld, Vaswani, Marko, and Shadmehr}}}
\bibcite{hollingworth1910central}{{31}{1910}{{Hollingworth}}{{}}}
\bibcite{hoyer2002interpreting}{{32}{2002}{{Hoyer and Hyv{\"a}rinen}}{{}}}
\bibcite{janitzky2015optogenetic}{{33}{2015}{{Janitzky et~al.}}{{Janitzky, Lippert, Engelhorn, Tegtmeier, Goldschmidt, Heinze, and Ohl}}}
\bibcite{jazayeri2010temporal}{{34}{2010}{{Jazayeri and Shadlen}}{{}}}
\bibcite{jiang2015principles}{{35}{2015}{{Jiang et~al.}}{{Jiang, Shen, Cadwell, Berens, Sinz, Ecker, Patel, and Tolias}}}
\bibcite{jo2016differential}{{36}{2016}{{Jo and Jung}}{{}}}
\bibcite{jordan2020opposing}{{37}{2020}{{Jordan and Keller}}{{}}}
\bibcite{jordan2023locus}{{38}{2023}{{Jordan and Keller}}{{}}}
\bibcite{keller2009neural}{{39}{2009}{{Keller and Hahnloser}}{{}}}
\bibcite{keller2018predictive}{{40}{2018}{{Keller and Mrsic-Flogel}}{{}}}
\bibcite{keller2012sensorimotor}{{41}{2012}{{Keller et~al.}}{{Keller, Bonhoeffer, and H{\"u}bener}}}
\bibcite{kiani2009representation}{{42}{2009}{{Kiani and Shadlen}}{{}}}
\bibcite{knill2004bayesian}{{43}{2004}{{Knill and Pouget}}{{}}}
\bibcite{kording2004bayesian}{{44}{2004}{{K{\"o}rding and Wolpert}}{{}}}
\bibcite{kutschireiter2023bayesian}{{45}{2023}{{Kutschireiter et~al.}}{{Kutschireiter, Basnak, Wilson, and Drugowitsch}}}
\bibcite{larkum2013cellular}{{46}{2013}{{Larkum}}{{}}}
\bibcite{lawson2021computational}{{47}{2021}{{Lawson et~al.}}{{Lawson, Bisby, Nord, Burgess, and Rees}}}
\bibcite{liakoni2021learning}{{48}{2021}{{Liakoni et~al.}}{{Liakoni, Modirshanechi, Gerstner, and Brea}}}
\bibcite{ma2006bayesian}{{49}{2006}{{Ma et~al.}}{{Ma, Beck, Latham, and Pouget}}}
\bibcite{markram2004interneurons}{{50}{2004}{{Markram et~al.}}{{Markram, Toledo-Rodriguez, Wang, Gupta, Silberberg, and Wu}}}
\bibcite{marshall2016pharmacological}{{51}{2016}{{Marshall et~al.}}{{Marshall, Mathys, Ruge, De~Berker, Dayan, Stephan, and Bestmann}}}
\bibcite{masset2020behavior}{{52}{2020}{{Masset et~al.}}{{Masset, Ott, Lak, Hirokawa, and Kepecs}}}
\bibcite{meirhaeghe2021precise}{{53}{}{{Meirhaeghe et~al.}}{{Meirhaeghe, Sohn, and Jazayeri}}}
\bibcite{mumford1992computational}{{54}{1992}{{Mumford}}{{}}}
\bibcite{murray2014hierarchy}{{55}{2014}{{Murray et~al.}}{{Murray, Bernacchia, Freedman, Romo, Wallis, Cai, Padoa-Schioppa, Pasternak, Seo, Lee, et~al.}}}
\bibcite{nadim2014neuromodulation}{{56}{2014}{{Nadim and Bucher}}{{}}}
\bibcite{o2010coding}{{57}{2010}{{O'Neill and Schultz}}{{}}}
\bibcite{o2012can}{{58}{2012}{{O\IeC {\textquoteright }Reilly et~al.}}{{O\IeC {\textquoteright }Reilly, Jbabdi, and Behrens}}}
\bibcite{o2022prediction}{{59}{2022}{{O\IeC {\textquoteright }Toole et~al.}}{{O\IeC {\textquoteright }Toole, Oyibo, and Keller}}}
\bibcite{pakan2018impact}{{60}{2018}{{Pakan et~al.}}{{Pakan, Currie, Fischer, and Rochefort}}}
\bibcite{pawlak2010timing}{{61}{2010}{{Pawlak et~al.}}{{Pawlak, Wickens, Kirkwood, and Kerr}}}
\bibcite{petzschner2011iterative}{{62}{2011}{{Petzschner and Glasauer}}{{}}}
\bibcite{pfeffer2013inhibition}{{63}{2013}{{Pfeffer et~al.}}{{Pfeffer, Xue, He, Huang, and Scanziani}}}
\bibcite{pouget2013probabilistic}{{64}{2013}{{Pouget et~al.}}{{Pouget, Beck, Ma, and Latham}}}
\bibcite{rakitin1998scalar}{{65}{1998}{{Rakitin et~al.}}{{Rakitin, Gibbon, Penney, Malapani, Hinton, and Meck}}}
\bibcite{rao1999predictive}{{66}{1999}{{Rao and Ballard}}{{}}}
\bibcite{ridley1981new}{{67}{1981}{{Ridley et~al.}}{{Ridley, Haystead, Baker, and Crow}}}
\bibcite{rowland2007bayesian}{{68}{2007}{{Rowland et~al.}}{{Rowland, Stanford, and Stein}}}
\bibcite{rudy2011three}{{69}{2011}{{Rudy et~al.}}{{Rudy, Fishell, Lee, and Hjerling-Leffler}}}
\bibcite{runyan2017distinct}{{70}{2017}{{Runyan et~al.}}{{Runyan, Piasini, Panzeri, and Harvey}}}
\bibcite{rushworth2008choice}{{71}{2008}{{Rushworth and Behrens}}{{}}}
\bibcite{rutishauser2015representation}{{72}{2015}{{Rutishauser et~al.}}{{Rutishauser, Ye, Koroma, Tudusciuc, Ross, Chung, and Mamelak}}}
\bibcite{rutishauser2018single}{{73}{2018}{{Rutishauser et~al.}}{{Rutishauser, Aflalo, Rosario, Pouratian, and Andersen}}}
\bibcite{soltani2019adaptive}{{74}{2019}{{Soltani and Izquierdo}}{{}}}
\bibcite{summerfield2011perceptual}{{75}{2011}{{Summerfield et~al.}}{{Summerfield, Behrens, and Koechlin}}}
\bibcite{swanson2019hiring}{{76}{2019}{{Swanson and Maffei}}{{}}}
\bibcite{tremblay2016gabaergic}{{77}{2016}{{Tremblay et~al.}}{{Tremblay, Lee, and Rudy}}}
\bibcite{urban2016somatostatin}{{78}{2016}{{Urban-Ciecko and Barth}}{{}}}
\bibcite{wallace1998multisensory}{{79}{1998}{{Wallace et~al.}}{{Wallace, Meredith, and Stein}}}
\bibcite{wester2014behavioral}{{80}{2014}{{Wester and McBain}}{{}}}
\bibcite{white2016neurons}{{81}{2016}{{White and Monosov}}{{}}}
\bibcite{wilmes2023uncertainty}{{82}{2023}{{Wilmes et~al.}}{{Wilmes, Petrovici, Sachidhanandam, and Senn}}}
\bibcite{wilson1972excitatory}{{83}{1972}{{Wilson and Cowan}}{{}}}
\bibcite{wong2023computational}{{84}{2023}{{Wong et~al.}}{{Wong, Braun, Malagarriga, Moehlis, Moreno~Bote, Pouget, and Louis}}}
\bibcite{yon2021precision}{{85}{2021}{{Yon and Frith}}{{}}}
\bibcite{yu2005uncertainty}{{86}{2005}{{Yu and Dayan}}{{}}}
\citation{hertag2022prediction}
\citation{wilson1972excitatory}
\@writefile{toc}{\contentsline {section}{\numberline {A}{\color {blue}\uwave {Detailed Methods}}}{21}{appendix.A}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}{\color {blue}\uwave {Network model}}}{21}{subsection.A.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.1.1}{\color {blue}\uwave {Prediction-error network model}}}{21}{subsubsection.A.1.1}}
\citation{wilson1972excitatory}
\newlabel{eq:RateEqINs}{{9}{22}{\DIFaddFL {Prediction-error network model}}{equation.A.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.1.2}{\color {blue}\uwave {Memory and variance neuron}}}{22}{subsubsection.A.1.2}}
\citation{pouget2013probabilistic}
\citation{hertag2022prediction}
\citation{hertag2022prediction}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.1.3}{\color {blue}\uwave {Weighted output}}}{23}{subsubsection.A.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}{\color {blue}\uwave {Connectivity}}}{23}{subsection.A.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.2.1}{\color {blue}\uwave {Connections between neurons of the PE circuit}}}{23}{subsubsection.A.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.2.2}{\color {blue}\uwave {Connections between the PE circuit and the M neuron}}}{23}{subsubsection.A.2.2}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {Gain factors for nPE and pPE neurons in three different mean-field networks (MFN). Each MFN differs with respect to the inputs onto SOM and VIP neurons. The interneurons either receive the feedforward (FF) or feedback (FB) input. All numbers are rounded to the first digit.}\relax }}{23}{table.caption.27}}
\newlabel{tab:gain_factors_MFN}{{1}{23}{\footnotesize {Gain factors for nPE and pPE neurons in three different mean-field networks (MFN). Each MFN differs with respect to the inputs onto SOM and VIP neurons. The interneurons either receive the feedforward (FF) or feedback (FB) input. All numbers are rounded to the first digit.}\relax }{table.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \DIFdelbeginFL  \DIFdelendFL  \DIFaddbeginFL  \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  Gain factors of nPE and pPE neurons in the population model.\newline  } \DIFaddendFL  {\DIFdelbeginFL  {\color {red}\sout {(A)}}{\color {red}\sout {Changes in }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {The logarithm of }}\DIFaddendFL  the \DIFdelbeginFL  {\color {red}\sout {baseline activity }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {gain factors }}\DIFaddendFL  of nPE \DIFaddbeginFL  {\color {blue}\uwave {(top) }}\DIFaddendFL  and pPE \DIFdelbeginFL  {\color {red}\sout {neurons for different interneurons targeted. 3 different mean-field networks are tested. }}\DIFdelendFL  (\DIFdelbeginFL  {\color {red}\sout {B}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {bottom}}\DIFaddendFL  ) \DIFdelbeginFL  {\color {red}\sout {Same as }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {neurons }}\DIFaddendFL  in \DIFdelbeginFL  {\color {red}\sout {(A) but for }}\DIFdelendFL  the \DIFdelbeginFL  {\color {red}\sout {gain of }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {population model from \unhbox \voidb@x \hbox {\citep  {hertag2022prediction}}\hskip 0pt. The network contains $67$ }}\DIFaddendFL  nPE \DIFaddbeginFL  {\color {blue}\uwave {neurons }}\DIFaddendFL  and \DIFaddbeginFL  {\color {blue}\uwave {$66$ }}\DIFaddendFL  pPE neurons. \DIFdelbeginFL  {\color {red}\sout {Simulation parameters}}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {The remaining excitatory neurons were not classified as PE neurons and were not connected to the $M$ neuron.}}}\relax }}{24}{figure.caption.28}}
\newlabel{fig:Fig_gains}{{6}{24}{\DIFdelbeginFL \DIFdelendFL \DIFaddbeginFL \footnotesize {\bf Gain factors of nPE and pPE neurons in the population model.\newline } \DIFaddendFL {\DIFdelbeginFL \DIFdelFL {(A)}\DIFdelFL {Changes in }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {The logarithm of }\DIFaddendFL the \DIFdelbeginFL \DIFdelFL {baseline activity }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {gain factors }\DIFaddendFL of nPE \DIFaddbeginFL \DIFaddFL {(top) }\DIFaddendFL and pPE \DIFdelbeginFL \DIFdelFL {neurons for different interneurons targeted. 3 different mean-field networks are tested. }\DIFdelendFL (\DIFdelbeginFL \DIFdelFL {B}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {bottom}\DIFaddendFL ) \DIFdelbeginFL \DIFdelFL {Same as }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {neurons }\DIFaddendFL in \DIFdelbeginFL \DIFdelFL {(A) but for }\DIFdelendFL the \DIFdelbeginFL \DIFdelFL {gain of }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {population model from \mbox {\citep {hertag2022prediction}}\hskip 0pt. The network contains $67$ }\DIFaddendFL nPE \DIFaddbeginFL \DIFaddFL {neurons }\DIFaddendFL and \DIFaddbeginFL \DIFaddFL {$66$ }\DIFaddendFL pPE neurons. \DIFdelbeginFL \DIFdelFL {Simulation parameters}\DIFdelendFL \DIFaddbeginFL \DIFaddFL {The remaining excitatory neurons were not classified as PE neurons and were not connected to the $M$ neuron.}}\relax }{figure.caption.28}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {$w_\mathrm  {X\leftarrow M}$ for the post-synaptic SOM and VIP neurons in all three mean-field networks considered.}\relax }}{24}{table.caption.29}}
\newlabel{tab:wXM}{{2}{24}{\footnotesize {$w_\mathrm {X\leftarrow M}$ for the post-synaptic SOM and VIP neurons in all three mean-field networks considered.}\relax }{table.caption.29}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.2.3}{\color {blue}\uwave {Connections between the PE circuit and the V neuron}}}{24}{subsubsection.A.2.3}}
\citation{hertag2022prediction}
\newlabel{eq:theta}{{14}{25}{\DIFadd {Connections between the PE circuit and the V neuron}}{equation.A.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}{\color {blue}\uwave {Inputs}}}{25}{subsection.A.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.4}{\color {blue}\uwave {Simulations}}}{25}{subsection.A.4}}
\@writefile{toc}{\contentsline {section}{\numberline {B}{\color {blue}\uwave {Supporting analyses}}}{26}{appendix.B}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1}{\color {blue}\uwave {Activity of M and V neuron in a simplified model}}}{26}{subsection.B.1}}
\newlabel{sec:toy}{{B.1}{26}{\DIFadd {Activity of M and V neuron in a simplified model}}{subsection.B.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2}{\color {blue}\uwave {Impact of PE neurons' gain on estimating mean and variance}}}{27}{subsection.B.2}}
\newlabel{sec:impact_gain}{{B.2}{27}{\DIFadd {Impact of PE neurons' gain on estimating mean and variance}}{subsection.B.2}{}}
\newlabel{sec:gain_impact}{{B.2}{27}{\DIFadd {Impact of PE neurons' gain on estimating mean and variance}}{subsection.B.2}{}}
\newlabel{eq:condition_mean_gain_equal}{{21}{27}{\DIFadd {Impact of PE neurons' gain on estimating mean and variance}}{equation.B.21}{}}
\newlabel{eq:prediction_gain}{{22}{27}{\DIFadd {Impact of PE neurons' gain on estimating mean and variance}}{equation.B.22}{}}
\newlabel{eq:condition_variance_gain}{{23}{27}{\DIFadd {Impact of PE neurons' gain on estimating mean and variance}}{equation.B.23}{}}
\newlabel{eq:variance_gain}{{25}{28}{\DIFadd {Impact of PE neurons' gain on estimating mean and variance}}{equation.B.25}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3}{\color {blue}\uwave {Impact of PE neurons' baseline on estimating mean and variance}}}{28}{subsection.B.3}}
\newlabel{sec:impact_baseline}{{B.3}{28}{\DIFadd {Impact of PE neurons' baseline on estimating mean and variance}}{subsection.B.3}{}}
\newlabel{eq:condition_baseline_mean}{{26}{28}{\DIFadd {Impact of PE neurons' baseline on estimating mean and variance}}{equation.B.26}{}}
\newlabel{eq:condition_baseline_mean_1}{{27}{28}{\DIFadd {Impact of PE neurons' baseline on estimating mean and variance}}{equation.B.27}{}}
\newlabel{eq:condition_baseline_variance}{{28}{28}{\DIFadd {Impact of PE neurons' baseline on estimating mean and variance}}{equation.B.28}{}}
\newlabel{eq:condition_baseline_variance_1}{{29}{28}{\DIFadd {Impact of PE neurons' baseline on estimating mean and variance}}{equation.B.29}{}}
\newlabel{eq:condition_baseline_variance_2}{{30}{28}{\DIFadd {Impact of PE neurons' baseline on estimating mean and variance}}{equation.B.30}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.4}{\color {blue}\uwave {Modelling the impact of neuromodulators on the sensory weight}}}{29}{subsection.B.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.5}{\color {blue}\uwave {Sensory weight and contraction bias}}}{29}{subsection.B.5}}
\@writefile{toc}{\contentsline {section}{\numberline {C}{\color {blue}\uwave {Supplementary Figures}}}{30}{appendix.C}}
\@writefile{lof}{\contentsline {figure}{\numberline {S1}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  Estimating mean and variance of different stimulus distributions.\newline  } {\color {blue}\uwave {Top: The normalised absolute difference between the averaged mean and the activity of the M neuron decreases to a near-zero level for all stimulus distributions tested. Bottom: The normalised absolute difference between the averaged variance and the activity of the V neuron decreases with small differences between the distributions tested. Parametrisation of the uniform distribution as in Fig. \ref  {fig:Fig_2}. }}\relax }}{31}{figure.caption.30}}
\newlabel{fig:Fig_2_S1}{{S1}{31}{\footnotesize {\bf Estimating mean and variance of different stimulus distributions.\newline } \DIFaddFL {Top: The normalised absolute difference between the averaged mean and the activity of the M neuron decreases to a near-zero level for all stimulus distributions tested. Bottom: The normalised absolute difference between the averaged variance and the activity of the V neuron decreases with small differences between the distributions tested. Parametrisation of the uniform distribution as in Fig. \ref {fig:Fig_2}. }\relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S2}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  Estimating mean and variance of sensory stimuli in a rate-based population network.\newline  } {\bf  {\color {blue}\uwave {(A)}}} {\color {blue}\uwave {Illustration of the rate-based population network and the stimuli over time. }}{\bf  {\color {blue}\uwave {(B)}}} {\color {blue}\uwave {M and V neuron activities over time for one example parameterisation. }}{\bf  {\color {blue}\uwave {(C)}}} {\color {blue}\uwave {The normalised absolute difference between the averaged mean and the activity of the M neuron (dark green) or between the averaged variance and the activity of the V neuron (brown) for uncorrelated deviations, that is, increasing SD of $\gamma $ (left), correlated deviations, that is, increasing mean of $\gamma $ (middle), and the network sparsity. }}\relax }}{31}{figure.caption.31}}
\newlabel{fig:Fig_2_S2}{{S2}{31}{\footnotesize {\bf Estimating mean and variance of sensory stimuli in a rate-based population network.\newline } {\bf \DIFaddFL {(A)}} \DIFaddFL {Illustration of the rate-based population network and the stimuli over time. }{\bf \DIFaddFL {(B)}} \DIFaddFL {M and V neuron activities over time for one example parameterisation. }{\bf \DIFaddFL {(C)}} \DIFaddFL {The normalised absolute difference between the averaged mean and the activity of the M neuron (dark green) or between the averaged variance and the activity of the V neuron (brown) for uncorrelated deviations, that is, increasing SD of $\gamma $ (left), correlated deviations, that is, increasing mean of $\gamma $ (middle), and the network sparsity. }\relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S3}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  Estimating mean and variance of spatial stimuli.\newline  } {\bf  {\color {blue}\uwave {(A)}}} {\color {blue}\uwave {Illustration of a network estimating the mean and variance of a stimulus that varies across space. To simulate selectivity, the network comprises $1000$ identical, uncoupled mean-field networks each receiving a different input value drawn from a uniform distribution. }}{\bf  {\color {blue}\uwave {(B)}}} {\color {blue}\uwave {Activity of M neuron (top) and V neuron (bottom) for 2 stimuli. The second stimulus does either differ in the mean (orange) or the variance (yellow) from the first stimulus (indicated in C). }}{\bf  {\color {blue}\uwave {(C)}}} {\color {blue}\uwave {The normalised absolute difference between the averaged mean and the activity of the M neuron (dark green, top) or between the averaged variance and the activity of the V neuron (brown, bottom) for a range of different stimulus statistics. The examples from B are shown with colored arrows and markers. }}\relax }}{32}{figure.caption.32}}
\newlabel{fig:Fig_2_S3}{{S3}{32}{\footnotesize {\bf Estimating mean and variance of spatial stimuli.\newline } {\bf \DIFaddFL {(A)}} \DIFaddFL {Illustration of a network estimating the mean and variance of a stimulus that varies across space. To simulate selectivity, the network comprises $1000$ identical, uncoupled mean-field networks each receiving a different input value drawn from a uniform distribution. }{\bf \DIFaddFL {(B)}} \DIFaddFL {Activity of M neuron (top) and V neuron (bottom) for 2 stimuli. The second stimulus does either differ in the mean (orange) or the variance (yellow) from the first stimulus (indicated in C). }{\bf \DIFaddFL {(C)}} \DIFaddFL {The normalised absolute difference between the averaged mean and the activity of the M neuron (dark green, top) or between the averaged variance and the activity of the V neuron (brown, bottom) for a range of different stimulus statistics. The examples from B are shown with colored arrows and markers. }\relax }{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S4}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  Dynamic variance estimation allows flexible adaptation to changes in the stimulus statistics and environment. \newline  } {\bf  {\color {blue}\uwave {(A)}}} {\color {blue}\uwave {Sensory weight for different input statistics. Numbers denote specific example statistics. Arrows denote the transitions between those statistics. }}{\bf  {\color {blue}\uwave {(B)}}} {\color {blue}\uwave {The sensory weight over time is shown for all transitions in (A). For the sake of clarity, we only show the trials 40 -60. The switch to new input statistics occurs at trial 50. Parameters are listed in the Supporting Information. }}\relax }}{32}{figure.caption.33}}
\newlabel{fig:Fig_3_S1}{{S4}{32}{\footnotesize {\bf Dynamic variance estimation allows flexible adaptation to changes in the stimulus statistics and environment. \newline } {\bf \DIFaddFL {(A)}} \DIFaddFL {Sensory weight for different input statistics. Numbers denote specific example statistics. Arrows denote the transitions between those statistics. }{\bf \DIFaddFL {(B)}} \DIFaddFL {The sensory weight over time is shown for all transitions in (A). For the sake of clarity, we only show the trials 40 -60. The switch to new input statistics occurs at trial 50. Parameters are listed in the Supporting Information. }\relax }{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S5}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  Perturbing the weighting of sensory inputs and predictions by altering network properties. \newline  } {\bf  {\color {blue}\uwave {(A)}}} {\color {blue}\uwave {The weights from the PE neurons to the M neuron in the lower-order subnetwork are scaled by a factor the 0.3 or 7, leading to a distorted sensory weight. If the update of the M neuron in the lower subnetwork is too slow ($\blacktriangleleft $), the prediction is overrated. If the update of the M neuron in the lower subnetwork is too fast ($\blacktriangleright $), the sensory input is overrated. }}{\bf  {\color {blue}\uwave {(B)}}} {\color {blue}\uwave {The precise activation function for the V neurons does not have a major impact on the sensory weight. Only for inputs with high stimulus variability, the sensory stimulus is slightly overrated when the quadratic activation function is replaced by a linear, rectified activation function. }}\relax }}{32}{figure.caption.34}}
\newlabel{fig:Fig_3_S2}{{S5}{32}{\footnotesize {\bf Perturbing the weighting of sensory inputs and predictions by altering network properties. \newline } {\bf \DIFaddFL {(A)}} \DIFaddFL {The weights from the PE neurons to the M neuron in the lower-order subnetwork are scaled by a factor the 0.3 or 7, leading to a distorted sensory weight. If the update of the M neuron in the lower subnetwork is too slow ($\blacktriangleleft $), the prediction is overrated. If the update of the M neuron in the lower subnetwork is too fast ($\blacktriangleright $), the sensory input is overrated. }{\bf \DIFaddFL {(B)}} \DIFaddFL {The precise activation function for the V neurons does not have a major impact on the sensory weight. Only for inputs with high stimulus variability, the sensory stimulus is slightly overrated when the quadratic activation function is replaced by a linear, rectified activation function. }\relax }{figure.caption.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S6}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  The impact of neuromodulators acting globally on groups of interneurons. \newline  } {\color {blue}\uwave {The sensory weight changes when groups of interneurons are targeted by a neuromodulator. Whether the sensory weight decreases or increases not also depends on the modulation strength (see Fig. \ref  {fig:Fig_4}) but also on how strongly which interneuron is targeted. As shown in Fig. \ref  {fig:Fig_4}, the sensory weight is pushed toward 0.5 if the VIP neuron is stimulated. The sensory weight generally decreases when PV neurons are the main target. Considered are two limit cases (upper row: more sensory-driven before modulation, lower row: more prediction-driven before modulation). The results are shown for three mean-field networks (see \ref  {fig:Fig_4}). }}\relax }}{33}{figure.caption.35}}
\newlabel{fig:Fig_4_S1}{{S6}{33}{\footnotesize {\bf The impact of neuromodulators acting globally on groups of interneurons. \newline } \DIFaddFL {The sensory weight changes when groups of interneurons are targeted by a neuromodulator. Whether the sensory weight decreases or increases not also depends on the modulation strength (see Fig. \ref {fig:Fig_4}) but also on how strongly which interneuron is targeted. As shown in Fig. \ref {fig:Fig_4}, the sensory weight is pushed toward 0.5 if the VIP neuron is stimulated. The sensory weight generally decreases when PV neurons are the main target. Considered are two limit cases (upper row: more sensory-driven before modulation, lower row: more prediction-driven before modulation). The results are shown for three mean-field networks (see \ref {fig:Fig_4}). }\relax }{figure.caption.35}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S7}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  The impact of neuromodulators acting locally on groups of interneurons. \newline  } {\bf  {\color {blue}\uwave {(A)}}} {\color {blue}\uwave {Sensory weight changes with neuromodulators acting on interneurons in the lower PE circuit. }}{\bf  {\color {blue}\uwave {(B)}}} {\color {blue}\uwave {Sensory weight changes with neuromodulators acting on interneurons in the higher PE circuit. In general, the changes in the sensory weight is the opposite of the changes seen for neuromodulators acting on the lower-level PE neurons. Simulation parameters, labels and colors as in Fig. \ref  {fig:Fig_4}. }}\relax }}{34}{figure.caption.36}}
\newlabel{fig:Fig_4_S2}{{S7}{34}{\footnotesize {\bf The impact of neuromodulators acting locally on groups of interneurons. \newline } {\bf \DIFaddFL {(A)}} \DIFaddFL {Sensory weight changes with neuromodulators acting on interneurons in the lower PE circuit. }{\bf \DIFaddFL {(B)}} \DIFaddFL {Sensory weight changes with neuromodulators acting on interneurons in the higher PE circuit. In general, the changes in the sensory weight is the opposite of the changes seen for neuromodulators acting on the lower-level PE neurons. Simulation parameters, labels and colors as in Fig. \ref {fig:Fig_4}. }\relax }{figure.caption.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S8}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  Biased mean and variance estimation by changing the baseline and the gain of nPE and pPE.} {\color {blue}\uwave {In a toy model, described in sections \ref  {sec:gain_impact} and \ref  {sec:impact_baseline}, the contribution of gain and baseline to the changes in the mean and variance estimation are summarized. The results are based on the Eqs. (\ref  {eq:prediction_gain}), (\ref  {eq:variance_gain}), (\ref  {eq:condition_baseline_mean_1}) and (\ref  {eq:condition_baseline_variance_2}). }}\relax }}{35}{figure.caption.37}}
\newlabel{fig:Fig_4_S3}{{S8}{35}{\footnotesize {\bf Biased mean and variance estimation by changing the baseline and the gain of nPE and pPE.} \DIFaddFL {In a toy model, described in sections \ref {sec:gain_impact} and \ref {sec:impact_baseline}, the contribution of gain and baseline to the changes in the mean and variance estimation are summarized. The results are based on the Eqs. (\ref {eq:prediction_gain}), (\ref {eq:variance_gain}), (\ref {eq:condition_baseline_mean_1}) and (\ref {eq:condition_baseline_variance_2}). }\relax }{figure.caption.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S9}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  The combined changes in baseline and gain of all PE neurons determine the shift in the snesory weight.\newline  } {\color {blue}\uwave {Whether and how a neuromodulator changes the sensory weight depends on the interneuron targeted and the effect this interneuron has on the baseline and gain of both PE neurons, which in turn does depend on the network it is embedded in. For small inputs, changes in the baseline dominate, while for large inputs, the changes in the gains dominate the shift in the sensory weight. }}\relax }}{35}{figure.caption.38}}
\newlabel{fig:Fig_4_S4}{{S9}{35}{\footnotesize {\bf The combined changes in baseline and gain of all PE neurons determine the shift in the snesory weight.\newline } \DIFaddFL {Whether and how a neuromodulator changes the sensory weight depends on the interneuron targeted and the effect this interneuron has on the baseline and gain of both PE neurons, which in turn does depend on the network it is embedded in. For small inputs, changes in the baseline dominate, while for large inputs, the changes in the gains dominate the shift in the sensory weight. }\relax }{figure.caption.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S10}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  Including scalar variability in the model \newline  } {\color {blue}\uwave {When scalar variability is included, that is, the stimulus standard deviation depends linearly on the stimulus mean, the bias is larger for stimuli drawn from the upper end of the stimulus distribution than from the lower end. }}\relax }}{35}{figure.caption.39}}
\newlabel{fig:Fig_5_S1}{{S10}{35}{\footnotesize {\bf Including scalar variability in the model \newline } \DIFaddFL {When scalar variability is included, that is, the stimulus standard deviation depends linearly on the stimulus mean, the bias is larger for stimuli drawn from the upper end of the stimulus distribution than from the lower end. }\relax }{figure.caption.39}{}}
