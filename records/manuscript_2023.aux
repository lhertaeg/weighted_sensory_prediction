\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{yon2021precision}
\citation{eliades2008neural,keller2009neural,ayaz2019layer,audette2021temporally}
\citation{rao1999predictive,keller2018predictive}
\citation{keller2012sensorimotor,attinger2017visuomotor,jordan2020opposing,audette2021temporally}
\citation{hertag2020learning,hertag2022prediction}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  Neural network model to track both the uncertainty of sensory inputs and predictions.\newline  } {\bf  (A)} Example illustration for context-dependent integration of information. Left: When walking down an unfamiliar staircase that is visible, the brain might rely solely on external sensory information. Middle: When walking down the same stairs without visual information, the brain might rely on predictions formed by previous experience. Right: When climbing down an unexplored mountain in foggy conditions, the brain might need to integrate sensory information and predictions simultaneously. {\bf  (B)} Illustration of a prediction-error (PE) circuit with both negative and positive PE (nPE/pPE) neurons that receive inhibition from three different inhibitory interneuron types: parvalbumin-expressing (PV), somatostatin-expressing (SOM), and vasoactive intestinal peptide-expressing (VIP) interneurons. Local excitatory connections are not shown for clarity. {\bf  (C)} Illustration of network model that estimates the mean and variance of the external sensory stimuli. The core of this network model is the PE circuit shown in (B). The lower-level V neuron encodes the variance, while the lower-level M neuron encodes the mean of the sensory input. {\bf  (D)} Same as in (C) but the feedforward input is the activity of the lower-level M neuron. \relax }}{2}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:Fig_1}{{1}{2}{\footnotesize {\bf Neural network model to track both the uncertainty of sensory inputs and predictions.\newline } {\bf (A)} Example illustration for context-dependent integration of information. Left: When walking down an unfamiliar staircase that is visible, the brain might rely solely on external sensory information. Middle: When walking down the same stairs without visual information, the brain might rely on predictions formed by previous experience. Right: When climbing down an unexplored mountain in foggy conditions, the brain might need to integrate sensory information and predictions simultaneously. {\bf (B)} Illustration of a prediction-error (PE) circuit with both negative and positive PE (nPE/pPE) neurons that receive inhibition from three different inhibitory interneuron types: parvalbumin-expressing (PV), somatostatin-expressing (SOM), and vasoactive intestinal peptide-expressing (VIP) interneurons. Local excitatory connections are not shown for clarity. {\bf (C)} Illustration of network model that estimates the mean and variance of the external sensory stimuli. The core of this network model is the PE circuit shown in (B). The lower-level V neuron encodes the variance, while the lower-level M neuron encodes the mean of the sensory input. {\bf (D)} Same as in (C) but the feedforward input is the activity of the lower-level M neuron. \relax }{figure.caption.2}{}}
\citation{hertag2020learning,hertag2022prediction}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  Prediction-error neurons as the basis for estimating mean and variance of sensory stimuli.\newline  } {\bf  (A)} Illustration of the inputs with which the network (Fig. \ref  {fig:Fig_1}C) is stimulated. Network is exposed to a sequence of constant stimuli drawn from a uniform distribution. {\bf  (B)} PE neuron activity hardly changes with stimulus strength (left) but strongly increases with stimulus variability (right). {\bf  (C)} Interneuron activity strongly changes with stimulus strength (left) but hardly changes with stimulus variability (right). {\bf  (D)} M neuron correctly encodes the mean of the sensory stimuli. Left: Illustration of the input synapses onto the M neuron. Middle: Activity of the M neuron over time for one example distribution (black start in right panel). Right: Normalised absolute difference between the averaged mean and the activity of the M neuron in the steady state for different parametrizations of the stimulus distribution. {\bf  (E)} V neuron correctly encodes the variance of the sensory stimuli. Left: Illustration of the input synapses onto the V neuron. Middle: Activity of the V neuron over time for one example distribution (black start in right panel). Right: Normalised absolute difference between the averaged variance and the activity of the V neuron in the steady state for different parametrizations of the stimulus distribution. \relax }}{3}{figure.caption.5}}
\newlabel{fig:Fig_2}{{2}{3}{\footnotesize {\bf Prediction-error neurons as the basis for estimating mean and variance of sensory stimuli.\newline } {\bf (A)} Illustration of the inputs with which the network (Fig. \ref {fig:Fig_1}C) is stimulated. Network is exposed to a sequence of constant stimuli drawn from a uniform distribution. {\bf (B)} PE neuron activity hardly changes with stimulus strength (left) but strongly increases with stimulus variability (right). {\bf (C)} Interneuron activity strongly changes with stimulus strength (left) but hardly changes with stimulus variability (right). {\bf (D)} M neuron correctly encodes the mean of the sensory stimuli. Left: Illustration of the input synapses onto the M neuron. Middle: Activity of the M neuron over time for one example distribution (black start in right panel). Right: Normalised absolute difference between the averaged mean and the activity of the M neuron in the steady state for different parametrizations of the stimulus distribution. {\bf (E)} V neuron correctly encodes the variance of the sensory stimuli. Left: Illustration of the input synapses onto the V neuron. Middle: Activity of the V neuron over time for one example distribution (black start in right panel). Right: Normalised absolute difference between the averaged variance and the activity of the V neuron in the steady state for different parametrizations of the stimulus distribution. \relax }{figure.caption.5}{}}
\citation{keller2018predictive}
\citation{LarkumXXX}
\citation{XXX}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  Estimating the uncertainty of both the sensory input and the prediction.\newline  } {\bf  (A)} Illustration of the stimulation protocol. The network is exposed to a sequence of stimuli (one stimulus per trial). To account for stimulus variability, each stimulus is represented by $10$ stimulus values drawn from a normal distribution. To account for the volatility of the environment, in each trial, the stimulus mean is drawn from a uniform distribution (denoted trial variability). {\bf  (B)} Illustration of how the weighted output is calculated. The sensory weight $\alpha $ lies between zero (system relies perfectly on prediction) and one (system relies solely on the sensory input). {\bf  (C)} Limit case example in which the stimulus variability is zero but the trial variability is high. Left: Illustration of the stimulation protocol. Middle: Weighted output follows closely the sensory stimuli. Right: Sensory weight (function of the variances, see B) close to 1, indicating that the network ignores the prediction. Input statistics shown in E. {\bf  (D)} Limit case example in which the stimulus variability is high but the trial variability is zero. Left: Illustration of the stimulation protocol. Middle: Weighted output pushed towards the mean of the sensory stimuli. Right: Sensory weight close to zero, indicating that the network ignores the sensory stimuli. Input statistics shown in E. {\bf  (E)} Sensory weight for different input statistics. Predictions are weighted more strongly when the stimulus variability is larger than the trial variability. {\bf  (F)} Sensory weight throughout a trial for two different trial durations. Predictions are weighted more strongly at the beginning of a new trial. \relax }}{5}{figure.caption.7}}
\newlabel{fig:Fig_3}{{3}{5}{\footnotesize {\bf Estimating the uncertainty of both the sensory input and the prediction.\newline } {\bf (A)} Illustration of the stimulation protocol. The network is exposed to a sequence of stimuli (one stimulus per trial). To account for stimulus variability, each stimulus is represented by $10$ stimulus values drawn from a normal distribution. To account for the volatility of the environment, in each trial, the stimulus mean is drawn from a uniform distribution (denoted trial variability). {\bf (B)} Illustration of how the weighted output is calculated. The sensory weight $\alpha $ lies between zero (system relies perfectly on prediction) and one (system relies solely on the sensory input). {\bf (C)} Limit case example in which the stimulus variability is zero but the trial variability is high. Left: Illustration of the stimulation protocol. Middle: Weighted output follows closely the sensory stimuli. Right: Sensory weight (function of the variances, see B) close to 1, indicating that the network ignores the prediction. Input statistics shown in E. {\bf (D)} Limit case example in which the stimulus variability is high but the trial variability is zero. Left: Illustration of the stimulation protocol. Middle: Weighted output pushed towards the mean of the sensory stimuli. Right: Sensory weight close to zero, indicating that the network ignores the sensory stimuli. Input statistics shown in E. {\bf (E)} Sensory weight for different input statistics. Predictions are weighted more strongly when the stimulus variability is larger than the trial variability. {\bf (F)} Sensory weight throughout a trial for two different trial durations. Predictions are weighted more strongly at the beginning of a new trial. \relax }{figure.caption.7}{}}
\citation{yon2021precision}
\citation{cardin2019functional,XXX}
\citation{hertag2022prediction}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  Neuromodulator-based shifts in the weighting of sensory inputs and predictions. \newline  } {\bf  (A)} Neuromodulators acting on the interneurons can shift the weighting of sensory inputs and predictions. The changes depend on the type of interneuron targeted and the modulation strength (here simulated through an additional excitatory input). Considered are two limit cases (upper row: more sensory-driven before modulation, lower row: more prediction-driven before modulation). The results are shown for three different PE circuits (denotes by different markers). {\bf  (B)} When SOM and VIP neurons are equally modulated, the sensory weight remains unaffected. {\bf  (C)} The V neurons' activities depend on the PE neurons. Hence, perturbing the nPE and pPE neurons changes the uncertainty estimation. While stimulating the lower PE neurons affects both the lower and higher-order V neurons (right), stimulating the higher-order PE neurons only affects the V neuron in the same subnetwork (left). {\bf  (D)} The V neuron activity, and hence the sensory weight, changes as a result of the modulated PE neuron activity. The PE neuron activity, on the other hand, changes as a result of the interneurons being modulated. The interneurons change the baseline (left) and the gain (right) of the PE neurons. Whether an interneuron increases or decreases the estimated variance depends on both factors. \relax }}{7}{figure.caption.9}}
\newlabel{fig:Fig_4}{{4}{7}{\footnotesize {\bf Neuromodulator-based shifts in the weighting of sensory inputs and predictions. \newline } {\bf (A)} Neuromodulators acting on the interneurons can shift the weighting of sensory inputs and predictions. The changes depend on the type of interneuron targeted and the modulation strength (here simulated through an additional excitatory input). Considered are two limit cases (upper row: more sensory-driven before modulation, lower row: more prediction-driven before modulation). The results are shown for three different PE circuits (denotes by different markers). {\bf (B)} When SOM and VIP neurons are equally modulated, the sensory weight remains unaffected. {\bf (C)} The V neurons' activities depend on the PE neurons. Hence, perturbing the nPE and pPE neurons changes the uncertainty estimation. While stimulating the lower PE neurons affects both the lower and higher-order V neurons (right), stimulating the higher-order PE neurons only affects the V neuron in the same subnetwork (left). {\bf (D)} The V neuron activity, and hence the sensory weight, changes as a result of the modulated PE neuron activity. The PE neuron activity, on the other hand, changes as a result of the interneurons being modulated. The interneurons change the baseline (left) and the gain (right) of the PE neurons. Whether an interneuron increases or decreases the estimated variance depends on both factors. \relax }{figure.caption.9}{}}
\citation{han2023behavior}
\citation{yon2021precision}
\citation{ernst2002humans}
\citation{yon2021precision}
\citation{pakan2018impact,han2023behavior}
\citation{yon2021precision}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  Mechanisms underlying the contraction bias.\newline  } {\bf  (A)} Contraction bias in the model for two different stimulus uncertainties depicted in the inset. Bias is defined as the weighted output minus the stimulus mean. The absolute value of the slope (see linear fit) is a measure of the bias. The larger the slope, the larger the bias. {\bf  (B)} As a consequence of the sensory weight, the slope increases with stimulus variability (bias increases) and decreases with trial variability (bias decreases). {\bf  (C)} Bias is independent of the trial variability when the stimulus variability is zero. {\bf  (D)} Bias is independent of the stimulus variability when the trial variability is zero. {\bf  (E)} The slope depends on the trial duration. \relax }}{9}{figure.caption.11}}
\newlabel{fig:Fig_5}{{5}{9}{\footnotesize {\bf Mechanisms underlying the contraction bias.\newline } {\bf (A)} Contraction bias in the model for two different stimulus uncertainties depicted in the inset. Bias is defined as the weighted output minus the stimulus mean. The absolute value of the slope (see linear fit) is a measure of the bias. The larger the slope, the larger the bias. {\bf (B)} As a consequence of the sensory weight, the slope increases with stimulus variability (bias increases) and decreases with trial variability (bias decreases). {\bf (C)} Bias is independent of the trial variability when the stimulus variability is zero. {\bf (D)} Bias is independent of the stimulus variability when the trial variability is zero. {\bf (E)} The slope depends on the trial duration. \relax }{figure.caption.11}{}}
\citation{herzfeld2014memory}
\citation{XXX}
\citation{cardin2019functional}
\citation{XXX}
\citation{ONeill Schultz,2010,XXX}
\citation{knill2004bayesian,Ma et al.,2006,2008}
\citation{masset2020behavior}
\citation{masset2020behavior}
\citation{soltani2019adaptive}
\citation{soltani2019adaptive}
\citation{soltani2019adaptive}
\citation{masset2020behavior}
\citation{bastos2012canonical,keller2018predictive}
\citation{bastos2012canonical,heindorf2022reduction}
\citation{o2022prediction}
\citation{eliades2008neural,keller2009neural,ayaz2019layer,audette2021temporally}
\citation{keller2012sensorimotor,attinger2017visuomotor,jordan2020opposing,audette2021temporally,Zmarz2016XXX?necessary}
\citation{keller2018predictive}
\citation{yon2021precision}
\citation{yon2021precision}
\citation{yon2021precision}
\citation{You and Dayan}
\citation{lawson2021computational}
\citation{lawson2021computational}
\citation{lawson2021computational}
\citation{yon2021precision}
\citation{jordan2023locus}
\citation{jordan2023locus}
\citation{KathaXXX}
\citation{wong2023computational}
\citation{o2012can}
\citation{o2012can}
\citation{o2012can}
\citation{o2012can}
\citation{o2012can}
\citation{soltani2019adaptive}
\citation{liakoni2021learning}
\citation{kutschireiter2023bayesian}
\bibstyle{naturemag}
\bibdata{References_HertaegWilmesClopath_2023}
\bibcite{yon2021precision}{{1}{}{{}}{{}}}
\bibcite{rao1999predictive}{{2}{}{{}}{{}}}
\bibcite{keller2018predictive}{{3}{}{{}}{{}}}
\bibcite{keller2012sensorimotor}{{4}{}{{}}{{}}}
\bibcite{attinger2017visuomotor}{{5}{}{{}}{{}}}
\bibcite{jordan2020opposing}{{6}{}{{}}{{}}}
\bibcite{audette2021temporally}{{7}{}{{}}{{}}}
\bibcite{hertag2020learning}{{8}{}{{}}{{}}}
\bibcite{hertag2022prediction}{{9}{}{{}}{{}}}
\bibcite{cardin2019functional}{{10}{}{{}}{{}}}
\bibcite{han2023behavior}{{11}{}{{}}{{}}}
\bibcite{ernst2002humans}{{12}{}{{}}{{}}}
\bibcite{pakan2018impact}{{13}{}{{}}{{}}}
\bibcite{herzfeld2014memory}{{14}{}{{}}{{}}}
\bibcite{knill2004bayesian}{{15}{}{{}}{{}}}
\bibcite{masset2020behavior}{{16}{}{{}}{{}}}
\bibcite{soltani2019adaptive}{{17}{}{{}}{{}}}
\bibcite{bastos2012canonical}{{18}{}{{}}{{}}}
\bibcite{heindorf2022reduction}{{19}{}{{}}{{}}}
\bibcite{o2022prediction}{{20}{}{{}}{{}}}
\bibcite{eliades2008neural}{{21}{}{{}}{{}}}
\bibcite{keller2009neural}{{22}{}{{}}{{}}}
\bibcite{ayaz2019layer}{{23}{}{{}}{{}}}
\bibcite{lawson2021computational}{{24}{}{{}}{{}}}
\bibcite{jordan2023locus}{{25}{}{{}}{{}}}
\bibcite{wong2023computational}{{26}{}{{}}{{}}}
\bibcite{o2012can}{{27}{}{{}}{{}}}
\bibcite{liakoni2021learning}{{28}{}{{}}{{}}}
\bibcite{kutschireiter2023bayesian}{{29}{}{{}}{{}}}
\bibcite{wilson1972excitatory}{{30}{}{{}}{{}}}
\citation{hertag2022prediction}
\citation{wilson1972excitatory}
\@writefile{toc}{\contentsline {section}{\numberline {A}Detailed Methods}{16}{appendix.A}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Network model}{16}{subsection.A.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.1.1}Prediction-error network model}{16}{subsubsection.A.1.1}}
\citation{wilson1972excitatory}
\newlabel{eq:RateEqINs}{{9}{17}{Prediction-error network model}{equation.A.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.1.2}Memory and variance neuron}{17}{subsubsection.A.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.1.3}Weighted output}{17}{subsubsection.A.1.3}}
\citation{hertag2022prediction}
\citation{hertag2022prediction}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Connectivity}{18}{subsection.A.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.2.1}Connections between neurons of the PE circuit}{18}{subsubsection.A.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.2.2}Connections between the PE circuit and the M neuron}{18}{subsubsection.A.2.2}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {Gain factors for nPE and pPE neurons in three different mean-field networks (MFN). Each MFN differs with respect to the inputs onto SOM and VIP neurons. The interneurons either receive the feedforward (FF) or feedback (FB) input. All numbers are rounded to the first digit.}\relax }}{18}{table.caption.21}}
\newlabel{tab:gain_factors_MFN}{{1}{18}{\footnotesize {Gain factors for nPE and pPE neurons in three different mean-field networks (MFN). Each MFN differs with respect to the inputs onto SOM and VIP neurons. The interneurons either receive the feedforward (FF) or feedback (FB) input. All numbers are rounded to the first digit.}\relax }{table.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  Gain factors of nPE and pPE neurons in the population model.\newline  } {The logarithm of the gain factors of nPE (top) and pPE (bottom) neurons in the population model from \citep  {hertag2022prediction}. The network contains $67$ nPE neurons and $66$ pPE neurons. The remaining excitatory neurons were not classified as PE neurons and were not connected to the $M$ neuron.}\relax }}{18}{figure.caption.22}}
\newlabel{fig:Fig_gains}{{6}{18}{\footnotesize {\bf Gain factors of nPE and pPE neurons in the population model.\newline } {The logarithm of the gain factors of nPE (top) and pPE (bottom) neurons in the population model from \citep {hertag2022prediction}. The network contains $67$ nPE neurons and $66$ pPE neurons. The remaining excitatory neurons were not classified as PE neurons and were not connected to the $M$ neuron.}\relax }{figure.caption.22}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {$w_\mathrm  {X\leftarrow M}$ for the post-synaptic SOM and VIP neurons in all three mean-field networks considered.}\relax }}{19}{table.caption.23}}
\newlabel{tab:wXM}{{2}{19}{\footnotesize {$w_\mathrm {X\leftarrow M}$ for the post-synaptic SOM and VIP neurons in all three mean-field networks considered.}\relax }{table.caption.23}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.2.3}Connections between the PE circuit and the V neuron}{19}{subsubsection.A.2.3}}
\newlabel{eq:theta}{{14}{19}{Connections between the PE circuit and the V neuron}{equation.A.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}Inputs}{19}{subsection.A.3}}
\citation{hertag2022prediction}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.4}Simulations}{20}{subsection.A.4}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Supporting analyses}{21}{appendix.B}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1}Activity of M and V neuron in a simplified model}{21}{subsection.B.1}}
\newlabel{sec:toy}{{B.1}{21}{Activity of M and V neuron in a simplified model}{subsection.B.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2}Impact of PE neurons' gain on estimating mean and variance}{22}{subsection.B.2}}
\newlabel{sec:impact_gain}{{B.2}{22}{Impact of PE neurons' gain on estimating mean and variance}{subsection.B.2}{}}
\newlabel{sec:gain_impact}{{B.2}{22}{Impact of PE neurons' gain on estimating mean and variance}{subsection.B.2}{}}
\newlabel{eq:condition_mean_gain_equal}{{21}{22}{Impact of PE neurons' gain on estimating mean and variance}{equation.B.21}{}}
\newlabel{eq:prediction_gain}{{22}{22}{Impact of PE neurons' gain on estimating mean and variance}{equation.B.22}{}}
\newlabel{eq:condition_variance_gain}{{23}{22}{Impact of PE neurons' gain on estimating mean and variance}{equation.B.23}{}}
\newlabel{eq:variance_gain}{{25}{22}{Impact of PE neurons' gain on estimating mean and variance}{equation.B.25}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3}Impact of PE neurons' baseline on estimating mean and variance}{22}{subsection.B.3}}
\newlabel{sec:impact_baseline}{{B.3}{22}{Impact of PE neurons' baseline on estimating mean and variance}{subsection.B.3}{}}
\newlabel{eq:condition_baseline_mean}{{26}{22}{Impact of PE neurons' baseline on estimating mean and variance}{equation.B.26}{}}
\newlabel{eq:condition_baseline_mean_1}{{27}{22}{Impact of PE neurons' baseline on estimating mean and variance}{equation.B.27}{}}
\newlabel{eq:condition_baseline_variance}{{28}{23}{Impact of PE neurons' baseline on estimating mean and variance}{equation.B.28}{}}
\newlabel{eq:condition_baseline_variance_1}{{29}{23}{Impact of PE neurons' baseline on estimating mean and variance}{equation.B.29}{}}
\newlabel{eq:condition_baseline_variance_2}{{30}{23}{Impact of PE neurons' baseline on estimating mean and variance}{equation.B.30}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.4}Modelling the impact of neuromodulators on the sensory weight}{23}{subsection.B.4}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\@writefile{toc}{\contentsline {subsection}{\numberline {B.5}Sensory weight and contraction bias}{24}{subsection.B.5}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Supplementary Figures}{24}{appendix.C}}
\@writefile{lof}{\contentsline {figure}{\numberline {S1}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  Estimating mean and variance of different stimulus distributions.\newline  } Top: The normalised absolute difference between the averaged mean and the activity of the M neuron decreases to a near-zero level for all stimulus distributions tested. Bottom: The normalised absolute difference between the averaged variance and the activity of the V neuron decreases with small differences between the distributions tested. Parametrisation of the uniform distribution as in Fig. \ref  {fig:Fig_2}. \relax }}{25}{figure.caption.24}}
\newlabel{fig:Fig_2_S1}{{S1}{25}{\footnotesize {\bf Estimating mean and variance of different stimulus distributions.\newline } Top: The normalised absolute difference between the averaged mean and the activity of the M neuron decreases to a near-zero level for all stimulus distributions tested. Bottom: The normalised absolute difference between the averaged variance and the activity of the V neuron decreases with small differences between the distributions tested. Parametrisation of the uniform distribution as in Fig. \ref {fig:Fig_2}. \relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S2}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  Estimating mean and variance of sensory stimuli in a rate-based population network.\newline  } {\bf  (A)} Illustration of the rate-based population network and the stimuli over time. {\bf  (B)} M and V neuron activities over time for one example parameterisation. {\bf  (C)} The normalised absolute difference between the averaged mean and the activity of the M neuron (dark green) or between the averaged variance and the activity of the V neuron (brown) for uncorrelated deviations, that is, increasing SD of $\gamma $ (left), correlated deviations, that is, increasing mean of $\gamma $ (middle), and the network sparsity. \relax }}{25}{figure.caption.25}}
\newlabel{fig:Fig_2_S2}{{S2}{25}{\footnotesize {\bf Estimating mean and variance of sensory stimuli in a rate-based population network.\newline } {\bf (A)} Illustration of the rate-based population network and the stimuli over time. {\bf (B)} M and V neuron activities over time for one example parameterisation. {\bf (C)} The normalised absolute difference between the averaged mean and the activity of the M neuron (dark green) or between the averaged variance and the activity of the V neuron (brown) for uncorrelated deviations, that is, increasing SD of $\gamma $ (left), correlated deviations, that is, increasing mean of $\gamma $ (middle), and the network sparsity. \relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S3}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  Estimating mean and variance of spatial stimuli.\newline  } {\bf  (A)} Illustration of a network estimating the mean and variance of a stimulus that varies across space. To simulate selectivity, the network comprises $1000$ identical, uncoupled mean-field networks each receiving a different input value drawn from a uniform distribution. {\bf  (B)} Activity of M neuron (top) and V neuron (bottom) for 2 stimuli. The second stimulus does either differ in the mean (orange) or the variance (yellow) from the first stimulus (indicated in C). {\bf  (C)} The normalised absolute difference between the averaged mean and the activity of the M neuron (dark green, top) or between the averaged variance and the activity of the V neuron (brown, bottom) for a range of different stimulus statistics. The examples from B are shown with colored arrows and markers. \relax }}{26}{figure.caption.26}}
\newlabel{fig:Fig_2_S3}{{S3}{26}{\footnotesize {\bf Estimating mean and variance of spatial stimuli.\newline } {\bf (A)} Illustration of a network estimating the mean and variance of a stimulus that varies across space. To simulate selectivity, the network comprises $1000$ identical, uncoupled mean-field networks each receiving a different input value drawn from a uniform distribution. {\bf (B)} Activity of M neuron (top) and V neuron (bottom) for 2 stimuli. The second stimulus does either differ in the mean (orange) or the variance (yellow) from the first stimulus (indicated in C). {\bf (C)} The normalised absolute difference between the averaged mean and the activity of the M neuron (dark green, top) or between the averaged variance and the activity of the V neuron (brown, bottom) for a range of different stimulus statistics. The examples from B are shown with colored arrows and markers. \relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S4}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  Dynamic variance estimation allows flexible adaptation to changes in the stimulus statistics and environment. \newline  } {\bf  (A)} Sensory weight for different input statistics. Numbers denote specific example statistics. Arrows denote the transitions between those statistics. {\bf  (B)} The sensory weight over time is shown for all transitions in (A). For the sake of clarity, we only show the trials 40 -60. The switch to new input statistics occurs at trial 50. Parameters are listed in the Supporting Information. \relax }}{26}{figure.caption.27}}
\newlabel{fig:Fig_3_S1}{{S4}{26}{\footnotesize {\bf Dynamic variance estimation allows flexible adaptation to changes in the stimulus statistics and environment. \newline } {\bf (A)} Sensory weight for different input statistics. Numbers denote specific example statistics. Arrows denote the transitions between those statistics. {\bf (B)} The sensory weight over time is shown for all transitions in (A). For the sake of clarity, we only show the trials 40 -60. The switch to new input statistics occurs at trial 50. Parameters are listed in the Supporting Information. \relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S5}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  Perturbing the weighting of sensory inputs and predictions by altering network properties. \newline  } {\bf  (A)} The weights from the PE neurons to the M neuron in the lower-order subnetwork are scaled by a factor the 0.3 or 7, leading to a distorted sensory weight. If the update of the M neuron in the lower subnetwork is too slow ($\blacktriangleleft $), the prediction is overrated. If the update of the M neuron in the lower subnetwork is too fast ($\blacktriangleright $), the sensory input is overrated. {\bf  (B)} The precise activation function for the V neurons does not have a major impact on the sensory weight. Only for inputs with high stimulus variability, the sensory stimulus is slightly overrated when the quadratic activation function is replaced by a linear, rectified activation function. \relax }}{26}{figure.caption.28}}
\newlabel{fig:Fig_3_S2}{{S5}{26}{\footnotesize {\bf Perturbing the weighting of sensory inputs and predictions by altering network properties. \newline } {\bf (A)} The weights from the PE neurons to the M neuron in the lower-order subnetwork are scaled by a factor the 0.3 or 7, leading to a distorted sensory weight. If the update of the M neuron in the lower subnetwork is too slow ($\blacktriangleleft $), the prediction is overrated. If the update of the M neuron in the lower subnetwork is too fast ($\blacktriangleright $), the sensory input is overrated. {\bf (B)} The precise activation function for the V neurons does not have a major impact on the sensory weight. Only for inputs with high stimulus variability, the sensory stimulus is slightly overrated when the quadratic activation function is replaced by a linear, rectified activation function. \relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S6}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  The impact of neuromodulators acting globally on groups of interneurons. \newline  } The sensory weight changes when groups of interneurons are targeted by a neuromodulator. Whether the sensory weight decreases or increases not also depends on the modulation strength (see Fig. \ref  {fig:Fig_4}) but also on how strongly which interneuron is targeted. As shown in Fig. \ref  {fig:Fig_4}, the sensory weight is pushed toward 0.5 if the VIP neuron is stimulated. The sensory weight generally decreases when PV neurons are the main target. Considered are two limit cases (upper row: more sensory-driven before modulation, lower row: more prediction-driven before modulation). The results are shown for three mean-field networks (see \ref  {fig:Fig_4}). \relax }}{27}{figure.caption.29}}
\newlabel{fig:Fig_4_S1}{{S6}{27}{\footnotesize {\bf The impact of neuromodulators acting globally on groups of interneurons. \newline } The sensory weight changes when groups of interneurons are targeted by a neuromodulator. Whether the sensory weight decreases or increases not also depends on the modulation strength (see Fig. \ref {fig:Fig_4}) but also on how strongly which interneuron is targeted. As shown in Fig. \ref {fig:Fig_4}, the sensory weight is pushed toward 0.5 if the VIP neuron is stimulated. The sensory weight generally decreases when PV neurons are the main target. Considered are two limit cases (upper row: more sensory-driven before modulation, lower row: more prediction-driven before modulation). The results are shown for three mean-field networks (see \ref {fig:Fig_4}). \relax }{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S7}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  The impact of neuromodulators acting locally on groups of interneurons. \newline  } {\bf  (A)} Sensory weight changes with neuromodulators acting on interneurons in the lower PE circuit. {\bf  (B)} Sensory weight changes with neuromodulators acting on interneurons in the higher PE circuit. In general, the changes in the sensory weight is the opposite of the changes seen for neuromodulators acting on the lower-level PE neurons. Simulation parameters, labels and colors as in Fig. \ref  {fig:Fig_4}. \relax }}{28}{figure.caption.30}}
\newlabel{fig:Fig_4_S2}{{S7}{28}{\footnotesize {\bf The impact of neuromodulators acting locally on groups of interneurons. \newline } {\bf (A)} Sensory weight changes with neuromodulators acting on interneurons in the lower PE circuit. {\bf (B)} Sensory weight changes with neuromodulators acting on interneurons in the higher PE circuit. In general, the changes in the sensory weight is the opposite of the changes seen for neuromodulators acting on the lower-level PE neurons. Simulation parameters, labels and colors as in Fig. \ref {fig:Fig_4}. \relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S8}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  Biased mean and variance estimation by changing the baseline and the gain of nPE and pPE.} In a toy model, described in XXX, the contribution of gain and baseline to the changes in the mean and variance estimation can be revealed. XXX Equations \relax }}{28}{figure.caption.31}}
\newlabel{fig:Fig_4_S3}{{S8}{28}{\footnotesize {\bf Biased mean and variance estimation by changing the baseline and the gain of nPE and pPE.} In a toy model, described in XXX, the contribution of gain and baseline to the changes in the mean and variance estimation can be revealed. XXX Equations \relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S9}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  The combined changes in baseline and gain of all PE neurons determine the shift in the snesory weight.\newline  } Whether and how a neuromodulator changes the sensory weight depends on the interneuron targeted and the effect this interneuron has on the baseline and gain of both PE neurons, which in turn does depend on the network it is embedded in. For small inputs, changes in the baseline dominate, while for large inputs, the changes in the gains dominate the shift in the sensory weight. \relax }}{29}{figure.caption.32}}
\newlabel{fig:Fig_4_S4}{{S9}{29}{\footnotesize {\bf The combined changes in baseline and gain of all PE neurons determine the shift in the snesory weight.\newline } Whether and how a neuromodulator changes the sensory weight depends on the interneuron targeted and the effect this interneuron has on the baseline and gain of both PE neurons, which in turn does depend on the network it is embedded in. For small inputs, changes in the baseline dominate, while for large inputs, the changes in the gains dominate the shift in the sensory weight. \relax }{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S10}{\ignorespaces \relax \fontsize  {8}{9.5}\selectfont  \abovedisplayskip 6\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 3\p@ plus\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\bf  Including scalar variability in the model \newline  } When scalar variability is included, that is, the stimulus standard deviation depends linearly on the stimulus mean, the bias is larger for stimuli drawn from the upper end of the stimulus distribution than from the lower end. \relax }}{29}{figure.caption.33}}
\newlabel{fig:Fig_5_S1}{{S10}{29}{\footnotesize {\bf Including scalar variability in the model \newline } When scalar variability is included, that is, the stimulus standard deviation depends linearly on the stimulus mean, the bias is larger for stimuli drawn from the upper end of the stimulus distribution than from the lower end. \relax }{figure.caption.33}{}}
